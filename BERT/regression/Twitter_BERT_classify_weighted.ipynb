{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_BERT_classify_weighted.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8y-mnelj6CGA"
      },
      "source": [
        "# Prepare data for Colab"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "akVdlx_66CGF",
        "colab": {}
      },
      "source": [
        "# prepare data as a string to be used by colab\n",
        "\n",
        "import pandas as pd\n",
        "abc = pd.read_excel(\"test_400_P1.xlsx\")\n",
        "\n",
        "import numpy as np\n",
        "arr = np.array(abc)\n",
        "\n",
        "content = abc.columns[0] + '\\t' + abc.columns[1]\n",
        "for i in range(len(arr)):\n",
        "    content += '\\n' + str(arr[i, 0]) + '\\t' + str(arr[i, 1])\n",
        "    \n",
        "content"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "p0uYuU2J6CGK",
        "colab": {}
      },
      "source": [
        "# run this in colab to prepare data !!!\n",
        "\n",
        "content = 'Contents\\tOpinion\\n\"Alright guys, juul break!\" Thanks, Mom!!\\t0\\nDoing hookah alone makes me a crackhead?\\t0\\n@bootyfinesserv3 Hookah is legit banned in this country I donâ€™t even know how they do it lol\\t1\\nI need to go get coals for my hookah. ğŸ˜© I ran out!\\t0\\nCastro exempted vaping from the HUD smoking ban, for which I am grateful.\\t1\\nLuschek stops in to talk to Gloria and sneak a few hits from his vape. She reminds him that his selfishness and apathy directly added to her sentence and cost Doggett her life. #OrangeIsTheNewBlack #OrangeForever\\t0\\nI havenâ€™t consumed alcohol or hookah in almost 3 days ğŸ™„ğŸ™„ğŸ™„ğŸ™„ this ainâ€™t it\\t1\\nMom and pop vape shop: Family Juuls.\\t0\\n@mikemcgowow Yeah having a partner in that shit is wicked helpful. Iâ€™ll just keep rage throwing my juul into a dumpster until it works\\t0\\nI need my own hookah.\\t1\\n@dannycarlson02 protect my right to juul\\t1\\ngoing have me a drink and puff me some hookah\\t0\\nHe put Essentia in the hookah ğŸ˜‚ is thatâ€™s not love I donâ€™t know what is\\t0\\nnew vape ğŸ˜ğŸ˜ğŸ˜‹\\t1\\nyang better hit a fuckin vape on stage I swear to got\\t0\\n@_paigesmith13 you act like im not gonna pass my juul down through the generations...\\t0\\n@chasssjanine I havenâ€™t bought my vape yet though :/\\t0\\nVape rig that looks like an AirPod caseâ„¢\\t0\\nQT @BFBIV: update: I found it outside, cleaned her up now shes good as new. ğŸ‘ğŸ¼ ; cant find my juul, panic attack ahead\\t0\\nCan somebody send a juul to Mexico please\\t0\\nBroke my phone so I have to go get a new one, popped my tire, lost my vape in a field, lost my charger, cut my body all up because I fell on a rock, called many people I shouldnâ€™t have, lost my clothes.. all last night. Donâ€™t drink\\t0\\n@AlanciaLynette Dawghouse I bet, some at the hookah lounge too?\\t0\\n@mattPFV Vape Nation Man\\t1\\nQT @Sizzilin_Stew: This is what theyâ€™ve been waiting for ; Boys Daddy is OFF the JuuL and onto the cigarettes\\t0\\nsome of you have never experienced getting anxiety ab asking if u can hit ur friends juul and its SHOWS.\\t0\\n@BretWeinstein You mean vaping Roundup is bad for me? Thanks California!\\t0\\n@jordaanblok I\\'m the discreet juul (What top are you wearing?)\\t0\\nQT @CDCTobaccoFree: Totally get the campaign against combustible and chewable tobacco but vape has been a good middle ground for recovering smokers. That kids use them is an issue of poor parenting. ; E-cigarettes contain nicotine, which can impact learning and memory. Learn the health risks for your young patients.\\t1\\nForever losing my juul wow\\t0\\nimagine not being able to go 5 min without ripping a juul and spending mad money on pods ,,,, couldnâ€™t be me sis ğŸ¤§\\t0\\nI canâ€™t tell if Iâ€™m still in Brooklyn ... Iâ€™m walking up franklin and niggas smoking hookah on the corner\\t0\\nQT @elfishh: 1. Vape 2. World of Rocks punch card 3. Perfume/cologne samples 4. Aveeno unscented lotion 5. OG Hot Topic â€œfriends with benefitâ€ card ; new personality quiz: describe yourself using 5 things that are probably in your purse/backpack/whatever at any given moment\\t0\\nwent to hit my vape but instead it was my water bottle so now iâ€™m drowning and stupid\\t1\\n@philterlabs @WeedFeed @TheWeedTube1 A lot of effort to hide the Smell . Vape pens almost no Oder\\t0\\n@NewsBreaking \\'The womanâ€™s boyfriend told investigators she used a marijuana vaping pen and had been to the ER three weeks before she died because of a chest infection.\\' So really it was a combo of tainted GMO type vape juice/or pen and her chest infection.\\t0\\n@castello2 @SuckMyMod @featherbear15 Before vaping was banned in my building though, I thought the ban was silly. I started reading because of that and changed my mind. Still willing to read, but it\\'s hard for me to dismiss the sources I already mentioned.\\t-1\\ni lost my fucking juul, my nail is messed up, its hot, AND im broke as fuck now so happy friday to me lol\\t0\\nI think I lost my juul and iâ€™m upset\\t0\\n@Simonee_99 ian never smokin on hookah again\\t-1\\n@tripndie me every time i juul\\t0\\nguys im coming at u with very sad news. i lost my jesus juul yesterday and i wanted everyone to know i will be mourning for a while. would appreciate some time to heal. thank u have a blessed day\\t0\\nWhen are they gonna come out with a juul emoji tho\\t0\\nupdate: I figured out how to get my vape mixture 2:1 cbd to juice ratio, now Iâ€™m exxxtra chill\\t1\\nI wanna b as passionate about something like people that stay up to date on the latest vape tech and shit\\t0\\nFuck a juul Im purchasing a vape lol\\t1\\nSex is great and all but have yâ€™all ever hit a juul pod when youâ€™re not used to high nicotine ğŸ‘€\\t1\\nI want to go to the hookah bar\\t0\\nQT @_kissmycass: We destroyed the planet with cigs and now weâ€™re going to do it with juuls? Yâ€™all are trash ; Idk who needs to hear this but... STOP THROWING YOUR EMPTY JUUL PODS ON THE FLOOR It is littering. They are thick hard plastic w chemicals and are the perfect size for animals to eat\\t-1\\nAll she do is smoke hookah ğŸ˜©ğŸ˜©\\t0\\nYou ever hit the hookah so hard you choke\\t0\\ni need mcdonaldâ€™s and garlic bread and juul pods fuck\\t0\\nVaping outside the Olive Garden like true American white trash\\t0\\n@SwaggerSouls Swags your gonna died with the next 2 weeks an kill everyone in that house for your juul In other words.. You fucking weak cunt give up now before its too late\\t-1\\nIâ€™m going to ask again do people inhale hookah?\\t0\\n@TimRunsHisMouth And harbor criminals, legalize marijuana and hand out hypodermic needles but donâ€™t you dare Juul.\\t1\\nImagine being an adult using a juul to quit smoking, and you really like mango pods, but a bunch of nicotine addicted 16 year old got your shit taken.\\t1\\nQT @CoachCookCHS: #Preach. ; It blows my mind the amount of young student athletes that are vaping. That stuff ruins an athleteâ€™s hard work. It destroys their stamina. Athletes, you do it because itâ€™s cool? You know what else is cool? Being able to play 4 quarters of a game and lead your team to a win.\\t-1\\n@PKBohan Coffee and my vape\\t0\\nQT @CAVBERNAH: ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ ; Yâ€™all not tired of blowing hookah smoke into your phone via snap!? Jeez Iâ€™m tiiiiiiide of seeing it\\t-1\\nIâ€™ve been cleaning/doing chores, listening to music all day and keep taking breaks to tweet and vape my cbd lmaooo\\t0\\ncan i hit someoneâ€™s juul\\t0\\n@twentyfourzz I bought a juul charger today ($10.95)\\t0\\n@AW_YouMad Cuz I canâ€™t do the hookah fr\\t0\\nâ€œDoes anyone have a fucking juul?â€™â€ @THEnolanhenly Also â€œbust down thotianaâ€ in the stockyards @Carson_Reed10\\t0\\n@VapinSquirrel @jsummers71 #vape #vapingsaveslives #vapefam Well put Ivanna ğŸ‘ˆğŸ‘ğŸ‘\\t1\\n@glorianna21 Not anymore :/ now itâ€™s bubba vape\\t0\\n@kittypurrzog I think the headline should be \"SF becomes the first US city to create a e-cig black market\"\\t0\\nI need to be completely naked , stomach on E , and sleep for like 6 hours straight and then wake up to being held and cuddled. And then make some lasagna or Meatballs. A little vape ğŸ’¨ wouldnâ€™t be bad either lmfao .\\t0\\nQT @SwiftOnSecurity: i was *not* on this call.... ; On a 40-person call and it sounded like someone forgot mute and took a monster bong hit. Weâ€™ll just go with hookah enthusiast...\\t0\\nif i had all the money back that iâ€™ve spent on juul pods iâ€™d be papered up ğŸ˜¶\\t0\\n@thisisbrookeb weâ€™re literally vape hot boxing your car\\t0\\nFor every gift giving holiday I get asked if Iâ€™d like Juul Pods.. is this a problem?!\\t0\\n@lilfryh Didnâ€™t say mango juul pods\\t0\\n@TweetsbyMontyy Hookah smoke\\t0\\nIf you juul, I will think lesser of you and make no apologies\\t-1\\n*charges my vape pen in the school library computers*\\t0\\nThey should replace Chuck Todd on Meet the Press with a sweating mason jar of hot dog-flavored vape juice\\t0\\nI brought a vape today. It was the most impulsive of impulse buys\\t0\\nReal friends let you borrow their juul charger @sav_hartmann\\t0\\n@yessiebabyyy Juulâ€™s are horrible, go to a vape shop and get a real mod\\t1\\nIon smoke vapes that aint come from a dispensary\\t0\\nOoooo them post shower juul rips, shit hits diffffferentttt\\t0\\niâ€™m in naperville with no juul charger .. who got me /:\\t0\\n@antihannaszn Them shits r like craxk tho fr they hit better than most Vapes\\t1\\nFinally 21â€¼ï¸ğŸ”¥ğŸ¤¯ Now I can finally go to a Queens hookah lounge ğŸŒ¶ğŸ™‡ğŸ½\\u200dâ™‚ï¸ I hope itâ€™s fun ğŸ˜³ğŸ™ğŸ½\\t0\\nJust so everyones up to date, my juul fell 38 floors and still works\\t1\\nhad juul and a bang for breakfast ğŸ¤ªâœŒğŸ¼\\t1\\nme a year ago: we GET IT you VAPE me now: *buys a vape pen*\\t1\\nToday I bought juul pods good big\\t0\\nIn Canada they call creme brulee juul pods just \"vanilla.\" Truly the land time forgot.\\t0\\nmy friend told me they were going to buy me a juul for my birthdayğŸ˜³\\t0\\nIm wylin if I propose to the school that I want to do a presentation about Hookah Negligence ?\\t-1\\n@johnaarellano I found your juul\\t0\\nQT @donnicholass: ğŸ—£ğŸ—£ğŸ—£ğŸ—£ğŸ—£ ; â€¢ DAY PARTY AT ZONA â€¢ NO COVER | $100 REG BOTTLES | $15 HOOKAH | $5 REFILLS | OUTSIDE PATIO | KITCHEN AVAILABLE ALL DAY! FMI CONTACT ME! Sounds by @DJDymand x @Deeejaybebo ğŸ™ŒğŸ¾\\t0\\n@JenaLuckman Probably have all the juul pods but no chargers... it is hell after all\\t0\\nNo one: Me holding out a vape pen: Moon prism power, make up! ğŸ’–ğŸŒ™âœ¨\\t0\\nhey guys whats a way to stop cravings instead of using juul\\t0\\n@afairyhoe Legit just switch to the gum or a vape already. Why? Because it\\'s healthier. Your literally sucking up tar smoke ontop of what your body is craving.\\t1\\nAnyone need some vape juice? I got a Fizzy Lemonade that I only used once. Not a big fan of it. 50 mg for $20.\\t0\\nme: *doesnâ€™t eat a meal until 5pm* also me: *chain smokes juul and black iced coffees* also also me: *is slut* also also also me: â€œwhy do i keep getting sick??â€\\t0\\nWhy canâ€™t I ping my JUUL\\t0\\nWash your hands before touching your face and drink plenty of water. And lay off that hookah\\t-1\\nI just got IDâ€™d for a juul charger like ?? Make sure Iâ€™m 18 years old so I can buy a charger plz\\t0\\n@DrThomasWhite @Mathews_Archery Glad you clarified what that pipe was. Originally thought you accidentaly left your vape stick in the picture ğŸ˜‚\\t0\\nQT @Mhern23: Why are you me lmao ; My phone feels so much skinnier without my juul holder.\\t0\\ncan someone explain what hookah is for me\\t0\\n50% off hookah @ Adolfoâ€™s tonight word around town\\t0\\n@XanderSX14 â€œThey be smacking thoâ€ DANK VAPES (Fuck that foo juice) fucken dollar tree as beaners lmao\\t0\\nSo it is now illegal to vape in San Francisco. It\\'s still 100% legal to shit on the street in San Francisco though.\\t1\\nItâ€™s funny cause the predominantly black high schools in Staten Island have metal detectors and all that cause theyâ€™re â€œdangerousâ€ meanwhile my cousin is 12 in a â€œgoodâ€ public school and thereâ€™s a white boy in his class thatâ€™s been trying to sell him juul pods. 12 YEARS OLD.\\t-1\\nim finna buy a hookah\\t0\\n@thedrunkpenguin I know a few that have quit using vaping they say the trick is to reduce the nicotine over time. I just never really enjoyed it that much, could never seem to find one that replicated actual cigarettes.\\t-1\\nNigga said â€œthe port taste better that the hookah â€œ ğŸ˜­ğŸ˜­ğŸ˜­\\t0\\nYour mcm thinks Juul is a beautiful baby name for his next daughter\\t0\\nStill canâ€™t believe my grandma threwmy vape awayğŸ˜‚\\t0\\n@bad_bitchski I honestly love my juul. The thought of having a cig now makes me feel gross\\t1\\nQT @KaylaaaasWorld: It made sense ğŸ˜‚ğŸ’€ ; @teyanapryor_ : I think I need to stand up, so the hookah can flow this way *points from head to toe* ğŸ˜‚ğŸ˜­\\t0\\nQT @oxymme: Omggg I felt this ; ima still smoke the hookah if itâ€™s not mint, Iâ€™m just gonna say â€œyou shouldâ€™ve got mintâ€ the whole time\\t0\\nPSA YET AGAIN ON THE CARTS. Not only are the DANK VAPES being copied but now KING PENS are too! Know wtf you are buying and be safe â¤ï¸\\t0\\nAnyone at #Bugcon2019 have a vape pen charger?! @bugmanetv\\t0\\n@axios It\\'s all those damn vapes and juuls. LOL\\t0\\nJust got my suegra to try my vape. She doesnâ€™t know it but sheâ€™s about to get plastered.\\t0\\nsome 6â€™5â€ dude with a juul and a glass of beer is standing next to me and iâ€™m already annoyed. heâ€™s come so close to elbowing my face\\t0\\ntalkin bout â€˜iLl nEvEr sMoKe a CiGâ€™ but use a juul. whole ass FOOL ğŸ¤£\\t-1\\n@idkimemotional Wow me too coffee and vape lol\\t0\\nWhere can I get a dope hookah Machine ?\\t0\\nthis guy just snapped me a video of dank vapes saying â€œlet me take you on a date and iâ€™ll give you a cartâ€ LOL â€œpesticides and dinner? ğŸ™ˆâ€\\t-1\\nWOW! I just found out about juul! ğŸ¤£ğŸ¤£\\t1\\n@chelseacomics You could always try vaping? I know they make pure CBD oil for that stuff, so youâ€™d cut down on additives. I know itâ€™s got a douche bag rep, but honestly vaping product helps me a lot.\\t1\\nWasn\\'t paying attention while filling my top-fill vape tank and squirted an entire tanks worth of juice down the chimney.\\t0\\nMy vape isnâ€™t charging and my juul is out. What ever did I do to deserve this shit\\t0\\nIf you see me vaping it\\'s for a solid cause, I\\'m trying hard to completely eliminate cigars cigarettes and tobacco out of my life. I hate vape but it\\'s honestly better for me than the 4 blacks I\\'d smoke a day.\\t1\\nmy little brother: you know what my favorite thing about this place is, weâ€™re the only two people without a vape or a crop top here, except you\\t0\\nI hope yâ€™all know that smoking hookah for even an hour is the equivalent to smoking 100+ cigarettes, but keep flexing for social media ğŸ˜‚\\t-1\\nHaving no juul pods makes me deceased\\t1\\n@thattxkid @cheatham_cody â€œstormy do your have your juul on you?â€ â€œcan i hit your juul?â€ ğŸ’€ğŸ’€ğŸ’€ğŸ’€ğŸ’€\\t0\\nI need a JuuL pod. Just one single pod.\\t0\\nHookah on the balcony\\t0\\njuul pods are 21 dollars in Tampa theyâ€™re 17 in Cleveland this is sum bullshit\\t0\\nQT @BigCripnAce: Felt this ; we need more weed friendly bars iâ€™m tryna smoke Tooka not no Hookah\\t0\\nsmoking juul at work cuz ima baaaddd person\\t0\\nAll this talk about banning Juul while cigarettes are still legalğŸ˜·\\t1\\nIf u wanna become the next millionaire plz make a find my juul app throw me like 20% cause i gave u the idea\\t0\\ni FT my mom and we both doing the same thing.. she was smoking a cig ğŸ¤¢ ( me hookah ) and sippin\\t0\\nIt works good but I hate that it doesnâ€™t match ğŸ™„ I swear Iâ€™m never letting anyone borrow my vape again\\t0\\ni cannot go anywhere without losing my juul\\t0\\nYo real quick does anyone know if my FitBit can track juul rips?\\t0\\nMy kid is eleven. At his dad\\'s house, he has had weed laced chocolate chips, and he\\'s been vaping.. my ex is such a fucking tool. He thinks I\\'m the fucking dead beat when he can\\'t even pay a-fucking-ttention! I\\'ll take legal steps if it doesn\\'t stop ğŸ˜¡\\t-1\\n@ManguPena And a hookah installed with a long as hose and and bucket full of ice with henny\\t0\\n@MakinnPlays Well I mean it is a vape pen just with thc oil so itâ€™s like any other vape that can cause respiratory issues.... but I need more research on â€œmarijuana overdoseâ€ is what Iâ€™m saying lmao\\t-1\\nQT @scottbudman: This is great and all but like... regular tobacco still kills people and has been around for muuuuch longer. And real talk, still got addicted to that without fruit loops flavoring ğŸ¤·ğŸ¼\\u200dâ™€ï¸ ; The first major city in the country to ban the sale of electronic cigarettes, San Francisco, is the home of Juul. SF also recently approved a ban on the sale of flavored tobacco and a tax on sugar-sweetened drinks.\\t1\\n@sadsagsun Nicotine at least in their posts. I donâ€™t like the idea of tobacco or vape (or even alcohol) companies advertising AT ALL. But I know thatâ€™s unrealistic and just my own opinion and canâ€™t really be enforced\\t-1\\n@kahlia_miller I lose my juul literally like every day\\t0\\nIâ€™ve had the same juul pod for two days you can tell @Crow_boi hasnâ€™t been around much ğŸ¤·ğŸ¼\\u200dâ™€ï¸ğŸ˜‚\\t0\\nSo I took my blazer off. The Mom that claims to of worked w #JasonBateman asks me what I had for dinner. I said some zucchini & a sliver of lemon cake ğŸ° The rest was meat based I believe. Idk ğŸ˜ But I may be the only one on set that misses my vape ğŸ’¨ğŸ˜ğŸ¥\\t0\\nQT @rustygunter: ğŸ˜† ; Guys that vape, do yâ€™all shave your pussy completely or leave a landing strip?\\t0\\n@BriannaMonetB What kind of hookah Hoe are you ğŸ¤¦ğŸ»\\u200dâ™€ï¸\\t0\\n@BearlyFit @MercanthonyTV @FaZeClan @ChampionUSA @Banks @enolagayepyro damn bro what vape you got\\t0\\nTexass vape xbox 2 #rapenotgood\\t0\\n@Sylvesssterr She threw up Vape Life for the Gang. ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£, they gonna box the whip and have sex ğŸ¤£ğŸ˜‚\\t0\\nill quit hitting my juul when people stop aggravating the FUCK out me.\\t0\\nComing up next on CCTV\\'s public channel (Comcast8/Verizon43) 6/24/2019 3:10:04 AM: Norfolk County Prevention Coalition on Vaping May2019\\t0\\n@GroverNorquist Banning baking shoots not kill those jobs. Those jobs do not require vaping.\\t0\\n@BRWN_EYEGURL It really looks nice . I love it down there too!!!! Lmaooo at hookah\\t0\\nUGHHH if ur gonA HAVE OFFbrand juul FREAKING pods WARN A BITCH be4 I order it on FREAKING Postmates\\t0\\nMy car is full of juul pods and Taco Bell sauces\\t0\\nI Love Hookah but that shit be a bitch to clean.\\t0\\n@Hiiiiii74 @projectxpatriot @greshstart @CDCTobaccoFree Please name the â€œchemicals.â€ Vaping 10 years and making my own eliquid for 9 of those, Iâ€™d like to compare my ingredients with what you have down\\t1\\nIf underage Juul use is such a big problem in America, why dont they just lower the legal maximum nicotine content for all E-Juices like they have in the EU? ğŸ¤¦ğŸ½\\u200dâ™‚ï¸ Not even a 20 year cigarette smoker needs 40+ mg to make the switch to E-cigs... @JUULvapor @Surgeon_General\\t-1\\nIf cigarette companies can\\'t advertise on TV I truly believe Vape companies should be barred as well... Just because you added a battery doesn\\'t make it any less dangerous....\\t-1\\nmy cousins dad got me a vape\\t0\\n@C0urtneyg0rd0n2 bout to do the same with my juul smh\\t0\\nIn the middle of a first degree murder sentencing (yes I lost) and my mother is texting me about the dangers of vaping and friggin popcorn lung. Need to work on boundaries.\\t0\\n@isitastranger sending u virtual vape clouds\\t0\\n@_jhezze @ExchangeLA Be careful tho. Because one time I was allowed in with my hat and vape. Next time no hat and no vape was allowed.\\t0\\nMy friend couldnâ€™t bring his vape in so now Iâ€™m alone at the dayclub whoâ€™s ready for some social anxiety tweets\\t0\\nQT @_anettt_: Anet after taking 5 hits ; I think Iâ€™ve had enough hookah for the rest of my life\\t0\\nStart your week off right with 10% off all Vape Cartridges and Batteries.\\t0\\nJust saw ray walking to St. Thomas holding and smoking a whole hookah. Man itâ€™s good to be back in Waterford\\t0\\n@InsidePMI @BBCNews @sfgov What percentage of former cigarette smokers who become e-cigarette smokers eventually quit smoking entirely? What percentage revert back or become dual users?\\t0\\n@JayPizzle88 @officialmcafee @money_alotta Thatâ€™s fucking awesome. I have trouble drawing stick people and artwork Iâ€™ve tried to produce on a computer involves several hours, f bombs, exhausted JUUL cartridges, and booze back when I drank and that is doing something as simple as photo shopping Johns head into a meme\\t0\\nIâ€™ve been using some version of #ecig since 2011... weâ€™ve owned a juice and boxmod company, sold it to a bigger co. Iâ€™m #burnedout with the #coils and #cotton and making or buying juice.\\t0\\nAnywhere you work theres always one vaping coworker that dyes their hair\\t0\\nIâ€™ll be at La Hookah Town on Vernor in SW Detroit tomorrow hosting my first event ğŸ¤Ÿ Vlogging the entire night. If your free come out and support ğŸ’¨âš¡ï¸ğŸ–¤\\t1\\nI feel so much better since Iâ€™ve been on Herbalife. & I quit smoking my Mod , I havenâ€™t smoked in like 3 weeks, & I was vaping 3 yrs\\t-1\\n@anulikesstars LE VAPE SHOP!!!!!! I AM OBSESSED. Is it a \"le juul\"? pls say yes/ pls inquire for me\\t1\\nQT @destinnybrownn: Same ğŸ¥´ ; I literally need to start taping my juul to my forehead bc this little hoe be hidingğŸ˜¡\\t0\\nQT @_malyxo: he do be cappin for the bird ; I promise you guys kylers the sweetest little ting IN PERSON online heâ€™s an asshole but at meets he just smiles and smokes hookah\\t0\\n@Saint_Grobian beef jerky flavored vape cartridges\\t0\\nThis hookah hitting so coo Itâ€™s crazy\\t1\\nYou ever just hit your juul upside down? Cuz same\\t0\\nCan you bring a vape pen on the plane?\\t0\\n@asvpxpatrick @faithyangelz Just vape lmao no nicotine\\t0\\n2019 is so fucked. The earth is dying, im in kuwait, OJ is on twitter, my mom owns a juul, whataburger gettin pimped out, schlitterbahn gone, can the simulation cut me a fucKING BREAK PLEASE\\t-1\\nReally wanna go smoke some hookah\\t0\\nSomeone buy this damn juul since i canâ€™t use it anymore â˜¹ï¸\\t0\\nQT @ZoeyHertz: i dont have a juul but does this apply to thc pens as well? ğŸ˜© ; I have been juuling for 2 years and now I have pre oral cancer. So stop juuling kids lol\\t-1\\nBold of you to assume I wanna smell your vape cloud\\t0\\nQT @truthorange: Your ads make me wanna start vaping out of spite ; Let\\'s just say it\\'s a lot harder to keep that inside stuff inside of you when you vape.\\t0\\nAustin just walked in and traded the dap pen for the juul and just dipped w out a wordğŸ˜‚ğŸ˜‚ğŸ˜‚ clutch\\t0\\n@DREWWESS @KHOU They are or theyâ€™re They are still breaking the law Vaping is also a health hazard.\\t-1\\nWhere yâ€™all buy them hookah pens? Iâ€™m tryna but my bestie one.\\t0\\nQT @EwdatsGROSS: please stop iâ€™m calling the police ; A juul My pussy ğŸ¤ You can hit it\\t0\\n@StefanDidak That\\'s just sad. I knew that SF had a drug problem, but that\\'s just straight up absurd. All the more so that they decided a vaping ban would be beneficial, rather than tackling that!\\t1\\nQT @DylDuplechain: This right here !!! ; why you gonna waste you money on juul pods of you cant even inhale the juul?\\t1\\nQT @bshj__: Making throat cancer a social experience ; Whatâ€™s the purpose of hookah??\\t-1\\n2016-18 hookah was always a motive ğŸ¤¦ğŸ½\\u200dâ™‚ï¸\\t0\\nItâ€™s always the ones with the big butts that canâ€™t dance in the club. Para que tienen ğŸ‘, just to show off and smoke hookah. Smh ğŸ¤¦ğŸ½\\u200dâ™‚ï¸\\t0\\nholy shit I left my juul in my jeans when I was washing them but I saved it just in time half way through the wash. God really does exsist. SHEEEESH\\t0\\nDriving a challenger and smoking strawberry jelly donut vape juice.. hide ya girl ğŸ‘€\\t0\\nâ€œ i donâ€™t Juul, I donâ€™t do cocaine but I use straws OKâ€\\t0\\natl done turned me to hookah thot ğŸ˜‚\\t0\\nWoke up today, drank some coffee, hit my juul, figured out that pigeon racing is a huge thing in China.. regular old Saturday..\\t0\\nIâ€™m gonna have to stick up on Juul pods before I go back to California Iâ€™m 20 but the smoking age is 21 oof\\t1\\nI need a new data plan on my juul\\t0\\n@BLUNTxBurner420 ğŸ™ŒğŸ™ŒğŸ™ŒğŸ™Œ FuCk DrInKiNg AlChoHol WhEn We CaN vApE iT!!!\\t0\\nThe family that vapes together stays together, clearly.\\t1\\n10 min into cleaning my room and I found my juul charger ğŸ’…\\t0\\nnothing like a post-coital juul\\t1\\nMOM DID YOU TAKE MY JUUL\\t0\\n@amberbloedel Juul has been 21 and up for quite some time now.... itâ€™s their policy if a shoo is caught selling to minors they wonâ€™t distribute to them anymore. Sept. All of Texas will be Tobacco 21+, but vapes will be 18+ unless the company policy is different\\t-1\\nhookah >>>>\\t0\\n@Sun_Daze_11 I wish someone backed me up when I tried to call someone out about vaping in my section last season. The usher said they didnâ€™t see it.\\t-1\\nQT @katebyrnepower: Thatâ€™s just chicago, baby ; Currently browsing the Logan square monument for my friendâ€™s juul that she lost while making out with a stranger that she met at the owl........Easy could never\\t0\\nnobody: my brain: hit ur juul\\t0\\n@NewYorker @jiatolentino Canâ€™t vape, but you can poop anywhere at your leisure.\\t0\\nanyone else who doesn\\'t care about spending time with their father wanna go to hookah tonight!\\t0\\nforbidden lovers: lip gloss, my vape\\t0\\nsimply due to my CBGa allergy. No one will have fun if I swell up like a puffer fish and have to go to the ER. Vape blends/oils without are perfectly fine provided you share ğŸ˜˜ also while there will be alcohol present, I will only allow one drink/flight at the brewery. SSC is key\\t0\\n@LivinginWhy Gotta go what ever creature you are, like me all trump supporters have businesses jobs etc , So it\\'s time to go to bed and get up and work now go vape take some money out of your mom\\'s wallet and go buy a pop good night loser\\t0\\n@HillaryClinton Anyone here into guns? Vaping?\\t0\\nYOOOO I JUS CAUGHT MY BROTHER WIT A JUUL IM FINNA BEAT THE SHIT OUTTA HIS ASS\\t-1\\nI think I just heard my husband ask â€œwhat is your favorite vapeâ€ in the other room so I guess I donâ€™t know who he is anymore.\\t-1\\n@MarlenaRodrigz I have 3 half empty cartridges and nothing to help me heat them up and suck smoke out of it. I ordered a nice big vape pen so I wonâ€™t keep losing them but Iâ€™m sober and irritable. Arg.\\t0\\ni completely HATE when people try to one up you on a shitty home life or bad situations. Iâ€™ve SEEN bad home lives and Iâ€™ve witnessed the conscious and subconscious trauma and pain a child goes through and trust me your mom taking away your juul isnâ€™t the same\\t-1\\nQT @MeGustaJoshua: I feel attacked. ; My stomach is killing me this morning Its almost as if Iced Coffee and Juul is not a meal replacement\\t0\\n@_Simbasworld I can\\'t believe in this day and age people are still smoking cancer sticks when they could be smoking or vaping trees ğŸ¤·\\u200dâ™€ï¸\\t1\\nMy juul friends.. whereâ€™s the cheapest place to buy a juul. I lost mine and Iâ€™m not trying to be dumb and spend $75 on one again from a vape shop.\\t1\\n@IamBroony Donâ€™t vape live longer\\t-1\\nQT @MsMeowkinz: Lmfaaaoooooooo yoooo I remember the daysğŸ¥´ğŸ¥´ğŸ¥´ ; smoked mad hookah this weekend, I sound like Tracy Morgan today ğŸ¥´\\t0\\nâ€œI go to the bathroom every 2 hours so I can hit my juulâ€\\t0\\ni made fun of people who vape for so long until they made a usb stick that curbs my desire to eat toothpaste\\t-1\\n@ItsAllAboutDe #VapeLyfe\\t0\\n@lachlan hate/rape/vape is Akin\\'s version of \"wake/bake/skate,\" perhaps\\t0\\nHey Wind Vapes thanks for the follow!\\t0\\nremember kids next month is no juul july. can you go the whole month without hitting your juul ğŸ˜³\\t-1\\n@neamhrialta If you own a juul this birthday should probably be your last\\t-1\\nTime to vibe to some music and have a good vape session ğŸ‘ŒğŸ¾ğŸ˜Œ\\t0\\nLol I think about vaping again all the time but I know Iâ€™m not financially stable enough to be addicted to nicotine.ğŸ¤¦ğŸ¾\\u200dâ™‚ï¸ğŸ˜­\\t0\\nQT @ayyebabygirl_: On God fr fr ; A paint and sip class, poetry slams, picnics in the park, cooking classes, wine tasting, hookah lounges, hiking, camping, road trips... ALL DATE IDEAS ID LOVE TO EXPERIENCE â¤ï¸\\t1\\nSo my vape keeps saying \"check batteries\" everytime I try to hit it Like I haven\\'t had a cigarette in over 2 months don\\'t do this to me now :/\\t0\\nâ€œKeeley you got $30 I can borrow?â€ â€œNo, why?â€ â€œoh someoneâ€™s selling their JUUL & I thought about buying itâ€-@KendalQuillen\\t0\\nQT @ZoeyHertz: v happy that i lost my juul for 6 months and it doesnâ€™t work now ; I have been juuling for 2 years and now I have pre oral cancer. So stop juuling kids lol\\t-1\\n@ISDM27 Me after a cbd vape hit\\t0\\nme and aspen have matching vapes..\\t0\\n@MenlionD U so fucking dirty for that lmao. Vaping is nasty and the loads of nicotine in it. You should try a wax pen next time . The stuff is weed rolled up in a pen.\\t-1\\nThe city of San Francisco has become the first city to BAN e-cigarettes. And the market leader, â€œJuulâ€ is based in San Francisco...I like where this is going ğŸ˜Š\\t0\\nQT @ItsSnowBeatz: ğŸ˜‚ğŸ˜­ ; This nigga Karlous said girls who smoke hookah pussy taste like volcano dust..DAWGğŸ˜‚ğŸ˜‚\\t0\\nQT @ScottGottliebMD: What did you do as FDA Commissioner to encourage this option? You could\\'ve called Mitch Zeller during any day of your tenure and told him to get working on this option. ; Vapes should seek to separate from products like JUUL to establish potential to help adults. Also, e-cig makers who donâ€™t suffer JUULs youth affliction should consider OTC pathway as option to secure market approval. There are options for small vape stores that target only adults\\t1\\n@PatriotMichaelO Hey Michael, Yes weâ€™re so sorry for the delay we should have these kinks worked out very soon. Thanks so so much for your support. What MG do you vape?\\t0\\n@randall__hill I have a vape so it makes it even worseğŸ¤£\\t0\\nWhat is the point of hookah fr ?\\t0\\n@DENlM_DADDY get a fucking vape loser\\t-1\\nAlex literally lost his juul last night... we went to Qt rn and they had it. ğŸ’¯\\t0\\ni wish i had friends, to smoke hookah withğŸ˜¢ğŸ™„.\\t0\\nMy bed is calling me... this rain not it lol I wanted hookah or a drink but fuck it\\t0\\n@TREESVlNYL *blows vape smoke trying to be cool* *brother ruins it by blowing it away* â€œADAMâ€\\t0\\nsome juul pods be like snap crackle pop\\t0\\nQT @FreshOj24: LMFAOOOOOOOOOO Im glad you know ; Dominican niggas from DR donâ€™t know how to pass the hookah.\\t0\\n@aptly_engineerd first there was juul now there is pussay, the only vape stick made with authentic vaginal mucus it will get you On\\t1\\nIf you had a dollar for everytime you open a snap theres a fat bitch twerking or hella hookah smoke how much money would you have\\t0\\n@baha100 They can lie. So they do. Meanwhile, vape companies are not allowed to tell the truth - that vaping is vastly safer than smoking...\\t1\\nRandom cute girl approached me but saw me vaping so she asked someone else for a lighter. This isnâ€™t the first time this happened to me... I shall carry a lighter at all times ğŸ¤”\\t0\\nLmfaoooooo 20$ dollar Hookah ????? How much for a re-fill? 5 DOLLARSSS ?? Lmfaooo ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\\t0\\n@BleacherReport @Sportsnet Someone should teach No 2 how to smoke a cigar @RealSkipBayless @Zico31700472 @RPZADO @YvesGWM @fanintoronto guess they didnâ€™t expect the win so they didnâ€™t practice this part - he is smoking a cigar like he is smoking a Hookah @nabilabouhabib\\t0\\nI love my vape pen. Baked like a potato. Totally a stoner yo! ğŸŒ¬ğŸŒ¿ğŸƒ\\t0\\nQT @demithacreator: Shisha ; What do smoke? Weed, SK, Arizona or Loud?\\t0\\ni once saw 8-9 girls join in union over one juul pod no cap\\t0\\nAnybody ever use coconut water in they hookah ?\\t0\\nI might be stupid but Iâ€™m not stupid enough to own a juul\\t-1\\nMe smoking a juul and drinking tequila in the bathroom of the jitney-the young Bitch ride clean donâ€™t it!\\t0\\nQT @JoshDuckBurton: I think Yang should rock a Hawaiian shirt and rip a Juul during the next segment #DemDebate #YangGang2020 ; Iâ€™m surprised Yang hasnâ€™t leaned backed and ripped a fat Juul while not wearing a tie and says â€œyeah, bro.â€ #DemDebate2 #DemocraticDebate\\t0\\nQT @amoeffner19: i took it home today ğŸ¥´ ; thereâ€™s a juul sitting in the office at work and iâ€™m the only manager that smokes them so it must be mine right??? should i grab it???\\t0\\n@JaiTheGuy3 My school smells like vape and marijuana all the time LOL\\t0\\nQT @ARPdidTHAT: @RachelKathryn__ ğŸ™„ğŸ™„ clocked ; White Claw is just Juul water.\\t0\\n@brandonco4 Juul idc but people who smoke cigarettes in traffic are assholes. Forcing me to put my AC on the button that makes it recycle the inside air? Die screaming motherfucker.\\t0\\nif you smoke virginia tobacco flavored juul pods iâ€™m just gonna go ahead and assume you smoke crack also\\t-1\\nFemale bathroom attendants generally donâ€™t seem to yell at you for vaping so based on that I believe we need more women in office\\t0\\ni still canâ€™t believe they took my full pack of cigs, lighter, AND my goddamn juul going through security...iâ€™m honestly more mad about that than anything else wtf\\t0\\ngood hookah lounges in atlanta?\\t0\\nQT @sardashhhhhhhhh: I don\\'t juul but love the optimism ; if the juul doth crackle...big problems we tackle\\t-1\\n@DrBobBullard Ugh! Juul does more then just rhyme with KOOL. (SMH)\\t0\\n@zookepermusic @DillonFrancis Now u canâ€™t be vaping enoughğŸ˜¤\\t0\\nSo tonight at work a coworker stole my vape mod. That thing was over $100... Iâ€™m so disappointed in humans.\\t0\\nhookah and drinks errday\\t0\\nCarts/vapes are trash. Iâ€™d rather just roll up\\t-1\\nHampton beach and Hookah, iâ€™m w itğŸ˜›\\t0\\nI have saved a shit ton of money already switching to a Juul and also I donâ€™t reek of cigarettes. Iâ€™ve had 2 cigarettes in the past 4 days and the week before it took me an entire week to smoke one pack. daddy is living.\\t1\\nQT @ARPdidTHAT: I feel attacked ; White Claw is just Juul water.\\t0\\nâ€œIs your teenager irrational and moody, like every teenager in the entire history of the human species? It must be that newfangled vaping!â€\\t0\\nStarting July 1, all Walmart and Sam\\'s Club locations will increase the minimum age for tobacco purchases to 21. The retailers will also stop selling the fruit-flavored vaping systems popular with teenagers. Will other companies follow suit? Read more via @USAToday.\\t0\\nPeople are fucking fiends now days, i could put a hit on someone for a Juul pod\\t0\\nQT @NessaTabasco: ğŸ¤¢ğŸ¤¢ ; Son how did i lose my juul last night\\t0\\n@meetdosist @ShopMedMen I tried the Calm first as I have some lung damage from lupus and wasn\\'t sure I\\'d be able to vape successfully. Now that I know I can, I plan to go back for the relief one for bedtime use. The MedMen rep was really helpful. PS: my cat LOVES the smell. LOL\\t1\\nQT @massisays_: Same but Iâ€™m also the hookah hogger ; I hate hookah hoggers\\t0\\nQT @johngraycpa: Dumbest tweet of the day? ; Wait a minute. Muslims in NE who own â€œHookahâ€ bars are NOT required to sell alcohol because alcohol is against their religious beliefs but Christian bakers in NE must bake cakes for LGBTQ even though itâ€™s against THEIR religious beliefs? No dbl standard or discrimination there?\\t0\\n@kyli_schmitt11 Someone literally stopped me yesterday to ask me for a hit of a vape, it was kinda sad tbh. I donâ€™t drink coffee or soda so when I have caffeine Iâ€™m wired\\t0\\nWoke up, looking for my vape pen. Found a cigarette instead with a hole in it. I fixed it with a piece of a Zig Zag paper. Just to let you all know how resourceful/borderline I really am.\\t0\\nâ€œAre you vaping in the house?â€ â€œNo itâ€™s just fabreeze!!â€\\t0\\nâ€˜Guy who smokes his juul and asks you if youâ€™ve ever had white clawâ€™ is the new â€˜girl with a teal Hydroflask telling you she still has ice in there since the day beforeâ€™\\t0\\n@PrettyNu1021 See u would know more about hookah than me didnâ€™t know thatâ€™s making ppl gain weight lol\\t0\\nDropped my juul in the toilet... bought a new one. Two days later did the same thing... fml\\t0\\ni laugh hard af when vape is life lol\\t0\\n@347Gabe im throwing ur juul out\\t0\\nI want a margarita and some hookah\\t0\\nQT @LeedyLauren: Everyone should know this by now ; PSA My friend was roofied last night at the Hookah Lounge in College Station. Thank god I was there to save her but PLEASE ladies donâ€™t take drinks from anyone!!! And keep an eye on your drink!!\\t0\\nme: just a pack of mint juul pods pls cashier: wow..show off me: cashier: me: cashier: ...$16.95\\t0\\nCrocs on my feet packinâ€™ that heat juul between my teeth thank you\\t0\\n@ShaalanBeg @PatelOncology @JackWestMD I think that ship has sailed and itâ€™s too late to make vaping a regulated and safe smoking cessation tool, too worked into the culture of teens (as the makers planned). I think banning is the only way to head this off now.\\t-1\\nwhy any of y\\'all vape when it\\'s probably killing you is beyond me. I\\'ll only fill my lungs with what god intended me to: latex paint and oxygen ğŸ‘‹ğŸ‘‹ğŸ‘‹\\t-1\\n@afrozekbeshir really @â€˜ing everyone with a juul broğŸ˜‚\\t0\\nthat juul buzz be hittin my feet more than anything no cap\\t0\\nrick ross voice sound like he been smoking hookah since birth.\\t0\\nIf my grandma buys me juul pods to join the air force should i do it?\\t0\\nPlatinum vapes really out here w a whole ass billboard ğŸ¥´\\t0\\n@curlymamaw @CDCTobaccoFree Only chemical in vaping is the nicotine. And you can get it without it.\\t1\\nfor someone who only hits the occasional social vape, I listen to steamroller TOO much\\t0\\nQT @cheydandelion: refillable pods / bigger pods would be cool too ; the juul company should start making their juuls to just have a usb charger on the bottom of the device itself. So u could just plug your juul straight into any USB port like in the car and never have to worry about losing that tiny little charging thing anymore.\\t0\\n@ARBryant4 Vape smells are gross\\t-1\\nA 13 year old girl smoking a juul just asked me where the after party is Itâ€™s 1PM clout kids are built DIFFERENT\\t-1\\nIG live is weird as hell to me. Imagine being at the club with your friends and instead of enjoying your time w your friends, u decide to broadcast tyourself sitting down smoking hookah saying â€œhi wassupâ€ every minute to random people who pop up.\\t0\\nQT @rustygunter: That\\'s great!ğŸ˜ğŸ˜ğŸ˜‚ğŸ¤£ ; Guys that vape, do yâ€™all shave your pussy completely or leave a landing strip?\\t0\\ngunna setup outside my old high school and sell juul pods to students out of my 2004 VW Jetta like the entrepreneur I am\\t0\\n@warmdamn Wait which is it the vaping or the 2 consecutive dates...\\t0\\nQT @AddieMarieP: Me tries to hangout with someone... Skinny girl with a nice smile: Iâ€™ve got my juul Me: ; Fucking cunt\\t0\\nBroke my vape pen at work ... but itâ€™s still hitting ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­\\t0\\nI hit the juul and i cant feel my feet rn ğŸ˜‚\\t0\\nThat hookah shit lame afff\\t-1\\nthereâ€™s nothing better than taking a crisp hit of my vape early in the morning ğŸ¤£\\t0\\n@aspirecigs #HappyFathersDay @oddworld911 ,@philbh77 ,@Alien_Semen ,@axelbeam ,@dr_amp815 ,@irwansyah_vape ,@ShadeyVapes\\t0\\nI wanna go to the hookah lounge but I got no friends lmao\\t0\\n@CNN @AngelusMerula There was a young man in NJ who was found slumped over in his car. His vape apparatus exploded and a small sliver of metal went through is carotid artery and he died before he could open the car door.\\t-1\\n@trippingpossum Sorry for the spam lol. I was taking it orally before, under the tongue and it just..wasn\\'t really lasting all that long. Now I have this vape pod thingy, and I can just take a few drags off of it when I start feeling anxious or tense and I feel a wave of calm flush over me pfft\\t1\\nDM me if you can sell me a vape cart in the estates\\t0\\n@SMOKTECHLOGY Iâ€™ve never had a vape because Iâ€™ve never thought to switch\\t-1\\n@B_Real Flowers for home. Vapes if traveling.\\t0\\n@geekyJustinLee Top 5 is pretty generous. Though I\\'m definitely above the dude whose emails I keep getting. He orders SO MUCH VAPE JUICE. When he\\'s not in court-ordered drug therapy.\\t0\\n@Marruccaaa On g after I used the vape my lungs big asf ğŸ˜‚ I was smoking that hoe for 5 min before I did that\\t0\\n@wendyvapes @enbflavor @ijoyglobal @Mike_Vapes @Winnie_hellvape That sounds amazing my friend Wendy...I actually am for once in the last 6 months going to be able to vape on my top ever favorite liquid put on this planet....MBYC Fried by SicBoy...I will be bringing it with me as I get admitted into the hospital today...I\\'m scared.. :-(\\t1\\nIâ€™m in Paris in the bathroom and my flight is boarding so I ran to the bathroom. Iâ€™m now on the toilet chugging the rest of my champagne and getting my vape hits in. Iâ€™m ashamed of myself\\t0\\nThe California Democratic Convention is sponsored by Uber, Visa, Juul, Fox, and AirBnB. WTAF? #CADem2019\\t-1\\nJust like in the movies, sitting up with a pillow against the headboard after incredible sex, smoking a Juul\\t1\\n@xowenm tell me why i thought he had a juul in his hand\\t0\\n@lethargicwaldo @cincynancy If you put your ear up to the can and are really silent, you can hear the Juul hit Kreygasm\\t0\\nIn fairness I was prob the 2010 equivalent of that kid that vapes in class\\t0\\n@tbformayor I fw hookah now ğŸ¤£ at first thought it was useless\\t0\\nthis is â€œno juul julyâ€ bitch\\t-1\\n@aaron_WALDRUP I hate it I hate all of it Also bring me a juul charger to work.....mine died n iâ€™m sad\\t0\\nThey putting round up in dank vapes ğŸ˜‚\\t0\\nGushers vape got me fried\\t0\\nSan Francisco has become the first US city to ban e-cigarette sales until their health effects are clearer. #Sirius XM 115\\t-1\\n@kkillah_x nobody goes outside so even if you did try to go to a bar or a hookah lounge theyâ€™re EMPTY so itâ€™s still not fun ğŸ˜‚ğŸ˜‚ğŸ˜‚ğŸ˜‚\\t0\\n@stelIhudg you have a juul addiction & i am glad i donâ€™t have a juul addiction ğŸ˜€\\t-1\\n@AmericanRose8 @Montchelle66 @charzdesigns @KassMiass @TexasChick1968 @khenry657 @ms_kux @PhoebeDRobinson @LJT_is_me @ElizabethQE20 @Elaines2cents @almostjingo @michael_szumega @surfagogo @multitasker333 @mizdonna @jskielb3 @JenniferKashani @DrLaura2th @CyndeVita @Natashasjam In Colorado you can buy the CBD oil, under tongue. No high, just the pain relief. You can buy at vape stores, donâ€™t even have to go to MMJ store. My neighbor has cancer and he says it helps!\\t1\\nWent to get coffee with my dad this morning. I talked him into buying a juul\\t0\\nno cops at pride just a guy named Travis in a deadpool snapback and his torrential vape clouds\\t0\\nSmoking a juul is not better than smoking cigarettes if youâ€™re pregnant you shouldnâ€™t be smoking. Not sorry. Your child being healthy should mean more than feeding a habit ğŸ¤·ğŸ¼\\u200dâ™€ï¸.\\t-1\\nboy dem vapes sumn serious i almost died\\t-1\\nTheoretically, you can put lean in a Juul.\\t0\\n@StoneHamlin If I ever compliment vaping, call the police because Iâ€™ve been kidnapped\\t-1\\nQT @addvsen: This is exactly why I stopped going and why the city of Austin decided to cut BOTG short with less concerts during summer. The new wave of ppl going/moving here are trash af people. ; last night after blues on the green, zilker was fucking TRASHED. iâ€™m talking juul pods, beer, to go boxes, bags...a lot of it within 100 feet of a trash can. a lot of you guys pretend to care about the earth for twitter points. only about 5 of us stayed to clean. fuck yâ€™all\\t-1\\nHeelys on, juul charged, hat backwards. Watch out world.\\t0\\n@jordan_gravelin @jbarro The percentage of teenagers vaping is growing by 50% a year...25% in 2017, 38% in 2018, and signs pointing towards 50-60% this year. Draconian measures worth considering to reverse this quickly.\\t-1\\n69 dollars for a hookah by the beach?! Shit better come with some oysters and henny.\\t0\\n@PPonsetto @FitzTheReporter @GreatDismal @truthorange Can\\'t fault them for trying, vaping is an epidemic with teens\\t-1\\nafter this last coil burns iâ€™m officially giving up vaping\\t-1\\nYou, a peasant: Vape Mod My girlfriendâ€™s mother, a god: Wireless Hookah ğŸ˜ˆğŸ˜ˆ\\t0\\nthis @buyIegaImeds vape i got is the shit i\\'m never buying any other CBD vape ever again\\t-1\\nQT @AmericanLungPA: Agreed! ; @RepRabb The U.S. Surgeon General recently declared youth e-cigarette use an epidemic. Now more than 1 in 4 high school students use e-cigarettes regularly. Now is not the time to defund Pennsylvaniaâ€™s tobacco prevention programs when they are needed most #SaveMSAinPA\\t-1\\nSeriously though, for a city with a retail vacancy crisis, and where small businesses are already struggling to survive, this is a death knell for a whole category of businessesâ€”vape storesâ€”and a huge hit to the city\\'s beloved corner stores\\t0\\n@BuddyGoodlet Iâ€™m thinking you mean Juul and I donâ€™t do that crap buddy.\\t-1\\nBefore hand I gave her a sweet smile but I got a b- itch face & google eyes in return. I kept smiling & brushed it off. Afterwards she comes army marching after me as I was vaping outside. Human behavior # 101 â€œarmy marchâ€ walking is a form of aggression.\\t0\\nNeed a hookah at home ğŸ˜©\\t1\\nLeft my damn juul in the rain and this must be what a real heartbreak feels like ğŸ˜£\\t0\\nit has been 24 hours since my lungs have had precious juul vapor in them. keep me in your thots & prayers\\t0\\n@lovemyman_ San Francisco outlaws vaping and plastic straws however permits heroin use, public defecation , and public sex displays. Taxes up 40% and highest gas tax in NATION. Wow..someone still lives there?\\t0\\nQT @MC_Cash75: .@KillEFFY but with a juul ; Just saw a wrestler do the HHH water bottle gimmick but with a vape pen.\\t0\\nQT @scottbudman: WTF San Francisco? You fascist demagogues just might wanna do bans on feces, urine, hypodermic needles & typhus in the streets. ; The first major city in the country to ban the sale of electronic cigarettes, San Francisco, is the home of Juul. SF also recently approved a ban on the sale of flavored tobacco and a tax on sugar-sweetened drinks.\\t0\\nWow only harlem would have hookah in a hair salon\\t0\\nTo be honest, I\\'m still #AgainstSmoking cigarettes and yet, I just started #vaping. Does this make me a hypocrite? ğŸ’¨\\t1\\nQT @tobaccodad: Mood ; Thinking about a vape cloud so massive that it blocks the sun for an hour\\t0\\nQT @BIGSANT: ğŸ˜‚ğŸ˜‚ğŸ˜‚ ; Your MCM smokes hookah.\\t0\\nSomeone just asked if anyone has a juul charger in our company-wide Slack.. millennials have officially taken over the workforce\\t0\\nQT @Alexlovesbooty1: bitch fuck you i texted you back ğŸ˜‚ ; Since you don\\'t wanna text me back bitch I left my juul pods in your car @xobabykaylee\\t0\\nQT @arimcneary: people are really out here addicted to a flash drive ; I knew I was more superior to my peers when they became juul addicts and I didnâ€™t\\t-1\\nQT @adam22: All of the above ğŸ¤·ğŸ¾\\u200dâ™‚ï¸ ; 2015 = molly 2016 = lean 2017 = xans 2018 = mango juul pods\\t0\\nwhat the hell kind of vapes in 2019\\t-1\\nMy grandparents geeneration used to smoke a cigarette after sex. Now we just hit the juul. ğŸ˜‚ #juul #facts\\t1\\n@MatthewWSmith2 What about juul pods and tide pods though\\t0\\nI feel like my juul is more addicting than cigarettes ever were. But idgaf cuz itâ€™s under half the cost of smoking and doesnâ€™t kill me!!!\\t1'\n",
        "\n",
        "file = open(\"input_data.txt\",\"w\") \n",
        " \n",
        "file.write(content)\n",
        " \n",
        "file.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZzVVWW5R6CGg"
      },
      "source": [
        "# Program begins"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "w6hs7_Ns6CGd",
        "colab": {}
      },
      "source": [
        "reweight = 5 # weight of a non-neutral tweet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PsX2gaGB6CGj",
        "outputId": "510c99f3-c9e0-48aa-b9ab-75854cffe573",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        }
      },
      "source": [
        "%%javascript\n",
        "IPython.notebook.clear_all_output();"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.clear_all_output();"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "aG_TiZvP6CGo",
        "outputId": "f9f4e3d2-477d-4744-ff74-c9e3748e256b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "#Installing BERT module\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: bert-tensorflow in /usr/local/lib/python3.6/dist-packages (1.0.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QO2K6xHy6CGr",
        "outputId": "df11eeb5-5120-47d0-89b4-fb76fb60bb27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (45.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "o0gVW9s46CGu",
        "outputId": "d70246c0-252a-4481-9817-e20624dd5158",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install tensorflow_hub"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (45.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "5UGUYWim6CGy",
        "outputId": "8f7cd424-f4b2-4f39-f384-1e65e522c43a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.0\n",
            "tensorflow_hub version :  0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "IVnBVegX6CG1",
        "outputId": "6d4373fd-1b1c-4ffd-f2c3-cac65be451b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Importing BERT modules\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "eHvDmRRC6CG5",
        "outputId": "09d1caeb-f5da-424e-fb1c-0c63e1248c43",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = 'model'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: model *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FsqfcpRG6CG8",
        "outputId": "e84fd53c-cb62-4ce4-cbad-f272f72c5da1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "# train = pd.read_excel(\"test_400_P1.xlsx\")\n",
        "train = pd.read_table(\"input_data.txt\")\n",
        "train['Opinion'].value_counts()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    282\n",
              "-1     63\n",
              " 1     55\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "gKc8dvwu6CG_",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test =  train_test_split(train, test_size = 0.2)\n",
        "train, val =  train_test_split(train, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "E1Q7P8IT6CHD",
        "outputId": "92446d33-093a-4760-82f4-b06926566ed4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Training set sample\n",
        "train.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Contents</th>\n",
              "      <th>Opinion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>UGHHH if ur gonA HAVE OFFbrand juul FREAKING p...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>I want to go to the hookah bar</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Mom and pop vape shop: Family Juuls.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>I hope yâ€™all know that smoking hookah for even...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>@DrBobBullard Ugh! Juul does more then just rh...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Contents  Opinion\n",
              "164  UGHHH if ur gonA HAVE OFFbrand juul FREAKING p...        0\n",
              "46                      I want to go to the hookah bar        0\n",
              "7                 Mom and pop vape shop: Family Juuls.        0\n",
              "133  I hope yâ€™all know that smoking hookah for even...       -1\n",
              "291  @DrBobBullard Ugh! Juul does more then just rh...        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nrqWnO3z6CHG",
        "outputId": "7ba7a32a-40bf-4989-9c62-2a82d0b40bf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train['Opinion'].value_counts()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    185\n",
              " 1     37\n",
              "-1     34\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "HLWtivfK6CHJ",
        "outputId": "c8fc1f9c-3ddc-4a5c-ce12-ce345e38ba53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "val['Opinion'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    42\n",
              "-1    15\n",
              " 1     7\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "V0g2PRcq6CHM",
        "outputId": "96e425c9-418d-4c9f-a25e-4887c038d59c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "test['Opinion'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    55\n",
              "-1    14\n",
              " 1    11\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Jdz-sOHy6CHO",
        "outputId": "9ced1742-e440-442a-e7c6-0a034dc591cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Validation Set Shape :\", val.shape)\n",
        "print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (256, 2)\n",
            "Validation Set Shape : (64, 2)\n",
            "Test Set Shape : (80, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bQUhpLZB6CHS",
        "outputId": "852a52b7-bd8c-404d-fed2-b9598f78c9f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Contents', 'Opinion'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "kRat49Ol6CHV",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'Contents'\n",
        "LABEL_COLUMN = 'Opinion'\n",
        "# The list containing all the classes (train['SECTION'].unique())\n",
        "label_list = [-1,0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "B9ZLroFQ6CHY",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WAIOGzFw6CHd",
        "outputId": "69cce24e-7fff-4c38-cc86-d543417cfbb2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "164    <bert.run_classifier.InputExample object at 0x...\n",
              "46     <bert.run_classifier.InputExample object at 0x...\n",
              "7      <bert.run_classifier.InputExample object at 0x...\n",
              "133    <bert.run_classifier.InputExample object at 0x...\n",
              "291    <bert.run_classifier.InputExample object at 0x...\n",
              "                             ...                        \n",
              "221    <bert.run_classifier.InputExample object at 0x...\n",
              "54     <bert.run_classifier.InputExample object at 0x...\n",
              "60     <bert.run_classifier.InputExample object at 0x...\n",
              "173    <bert.run_classifier.InputExample object at 0x...\n",
              "79     <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 256, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "PGW6LyD96CHg",
        "outputId": "ad9b31fd-54c0-460a-ab84-cfa8f5323498",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  UGHHH if ur gonA HAVE OFFbrand juul FREAKING pods WARN A BITCH be4 I order it on FREAKING Postmates\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3RE5vjy-6CHj",
        "outputId": "94bd7350-a8fb-4473-b157-abe6250b0d92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YIdwlHwz6CHm",
        "outputId": "8551ee0a-a731-4c68-c6d0-705ad0ced9f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['u', '##gh', '##hh', 'if', 'ur', 'go', '##na', 'have', 'off', '##brand', 'ju', '##ul', 'freaking', 'pods', 'warn', 'a', 'bitch', 'be', '##4', 'i', 'order', 'it', 'on', 'freaking', 'post', '##mates']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_097tfAR6CHp",
        "outputId": "72f0b614-262c-48b2-d02c-28b920cecf35",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 144\n",
        "\n",
        "# Convert our train and validation features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 256\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] u ##gh ##hh if ur go ##na have off ##brand ju ##ul freaking pods warn a bitch be ##4 i order it on freaking post ##mates [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] u ##gh ##hh if ur go ##na have off ##brand ju ##ul freaking pods warn a bitch be ##4 i order it on freaking post ##mates [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1057 5603 23644 2065 24471 2175 2532 2031 2125 23544 18414 5313 13847 26723 11582 1037 7743 2022 2549 1045 2344 2009 2006 13847 2695 15416 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1057 5603 23644 2065 24471 2175 2532 2031 2125 23544 18414 5313 13847 26723 11582 1037 7743 2022 2549 1045 2344 2009 2006 13847 2695 15416 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i want to go to the hook ##ah bar [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i want to go to the hook ##ah bar [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2215 2000 2175 2000 1996 8103 4430 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2215 2000 2175 2000 1996 8103 4430 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] mom and pop va ##pe shop : family ju ##uls . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] mom and pop va ##pe shop : family ju ##uls . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3566 1998 3769 12436 5051 4497 1024 2155 18414 28426 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3566 1998 3769 12436 5051 4497 1024 2155 18414 28426 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i hope y â€™ all know that smoking hook ##ah for even an hour is the equivalent to smoking 100 + cigarettes , but keep flex ##ing for social media [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i hope y â€™ all know that smoking hook ##ah for even an hour is the equivalent to smoking 100 + cigarettes , but keep flex ##ing for social media [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 3246 1061 1521 2035 2113 2008 9422 8103 4430 2005 2130 2019 3178 2003 1996 5662 2000 9422 2531 1009 15001 1010 2021 2562 23951 2075 2005 2591 2865 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 3246 1061 1521 2035 2113 2008 9422 8103 4430 2005 2130 2019 3178 2003 1996 5662 2000 9422 2531 1009 15001 1010 2021 2562 23951 2075 2005 2591 2865 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ dr ##bo ##bb ##ulla ##rd u ##gh ! ju ##ul does more then just rhyme with ko ##ol . ( sm ##h ) [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ dr ##bo ##bb ##ulla ##rd u ##gh ! ju ##ul does more then just rhyme with ko ##ol . ( sm ##h ) [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2852 5092 10322 22187 4103 1057 5603 999 18414 5313 2515 2062 2059 2074 20622 2007 12849 4747 1012 1006 15488 2232 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2852 5092 10322 22187 4103 1057 5603 999 18414 5313 2515 2062 2059 2074 20622 2007 12849 4747 1012 1006 15488 2232 1007 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ add ##vs ##en : this is exactly why i stopped going and why the city of austin decided to cut bot ##g short with less concerts during summer . the new wave of pp ##l going / moving here are trash af people . ; last night after blues on the green , z ##il ##ker was fucking trash ##ed . i â€™ m talking ju ##ul pods , beer , to go boxes , bags . . . a lot of it within 100 feet of a trash can . a lot of you guys pretend to care about the earth for twitter points . only about 5 of us stayed to clean . fuck y â€™ all [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ add ##vs ##en : this is exactly why i stopped going and why the city of austin decided to cut bot ##g short with less concerts during summer . the new wave of pp ##l going / moving here are trash af people . ; last night after blues on the green , z ##il ##ker was fucking trash ##ed . i â€™ m talking ju ##ul pods , beer , to go boxes , bags . . . a lot of it within 100 feet of a trash can . a lot of you guys pretend to care about the earth for twitter points . only about 5 of us stayed to clean . fuck y â€™ all [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 5587 15088 2368 1024 2023 2003 3599 2339 1045 3030 2183 1998 2339 1996 2103 1997 5899 2787 2000 3013 28516 2290 2460 2007 2625 6759 2076 2621 1012 1996 2047 4400 1997 4903 2140 2183 1013 3048 2182 2024 11669 21358 2111 1012 1025 2197 2305 2044 5132 2006 1996 2665 1010 1062 4014 5484 2001 8239 11669 2098 1012 1045 1521 1049 3331 18414 5313 26723 1010 5404 1010 2000 2175 8378 1010 8641 1012 1012 1012 1037 2843 1997 2009 2306 2531 2519 1997 1037 11669 2064 1012 1037 2843 1997 2017 4364 9811 2000 2729 2055 1996 3011 2005 10474 2685 1012 2069 2055 1019 1997 2149 4370 2000 4550 1012 6616 1061 1521 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 5587 15088 2368 1024 2023 2003 3599 2339 1045 3030 2183 1998 2339 1996 2103 1997 5899 2787 2000 3013 28516 2290 2460 2007 2625 6759 2076 2621 1012 1996 2047 4400 1997 4903 2140 2183 1013 3048 2182 2024 11669 21358 2111 1012 1025 2197 2305 2044 5132 2006 1996 2665 1010 1062 4014 5484 2001 8239 11669 2098 1012 1045 1521 1049 3331 18414 5313 26723 1010 5404 1010 2000 2175 8378 1010 8641 1012 1012 1012 1037 2843 1997 2009 2306 2531 2519 1997 1037 11669 2064 1012 1037 2843 1997 2017 4364 9811 2000 2729 2055 1996 3011 2005 10474 2685 1012 2069 2055 1019 1997 2149 4370 2000 4550 1012 6616 1061 1521 2035 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] va ##pe rig that looks like an air ##pod case ##â„¢ [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] va ##pe rig that looks like an air ##pod case ##â„¢ [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12436 5051 19838 2008 3504 2066 2019 2250 27633 2553 30108 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 12436 5051 19838 2008 3504 2066 2019 2250 27633 2553 30108 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] if you smoke virginia tobacco flavor ##ed ju ##ul pods i â€™ m just gonna go ahead and assume you smoke crack also [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] if you smoke virginia tobacco flavor ##ed ju ##ul pods i â€™ m just gonna go ahead and assume you smoke crack also [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2065 2017 5610 3448 9098 14894 2098 18414 5313 26723 1045 1521 1049 2074 6069 2175 3805 1998 7868 2017 5610 8579 2036 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2065 2017 5610 3448 9098 14894 2098 18414 5313 26723 1045 1521 1049 2074 6069 2175 3805 1998 7868 2017 5610 8579 2036 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ den ##lm _ daddy get a fucking va ##pe loser [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ den ##lm _ daddy get a fucking va ##pe loser [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 7939 13728 1035 8600 2131 1037 8239 12436 5051 10916 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 7939 13728 1035 8600 2131 1037 8239 12436 5051 10916 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bold of you to assume i wanna smell your va ##pe cloud [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] bold of you to assume i wanna smell your va ##pe cloud [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7782 1997 2017 2000 7868 1045 10587 5437 2115 12436 5051 6112 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 7782 1997 2017 2000 7868 1045 10587 5437 2115 12436 5051 6112 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "I8S539sx6CHr",
        "outputId": "3d2c1275-0f96-43c0-cf4c-de3bd7692c07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Example on first observation in the training set\n",
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence :  UGHHH if ur gonA HAVE OFFbrand juul FREAKING pods WARN A BITCH be4 I order it on FREAKING Postmates\n",
            "------------------------------\n",
            "Tokens :  ['u', '##gh', '##hh', 'if', 'ur', 'go', '##na', 'have', 'off', '##brand', 'ju', '##ul', 'freaking', 'pods', 'warn', 'a', 'bitch', 'be', '##4', 'i', 'order', 'it', 'on', 'freaking', 'post', '##mates']\n",
            "------------------------------\n",
            "Input IDs :  [101, 1057, 5603, 23644, 2065, 24471, 2175, 2532, 2031, 2125, 23544, 18414, 5313, 13847, 26723, 11582, 1037, 7743, 2022, 2549, 1045, 2344, 2009, 2006, 13847, 2695, 15416, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lNUQEO_A6CHu",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "    shifted = tf.cast(labels - 1, dtype = tf.float32) #<------------ labels: [0, 1, 2] => [-1, 0, 1]\n",
        "    weights0 = tf.abs(shifted * (reweight - 1)) #<------------------------\n",
        "    weights1 = weights0 + 1.0 #<------------------------\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(weights1 * per_example_loss) #<------------------------\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wxL15Uo66CHw",
        "colab": {}
      },
      "source": [
        "#A function that adapts our model to work for training, evaluation, and prediction.\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ckvs5eOy6CH2",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 50.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 30\n",
        "SAVE_SUMMARY_STEPS = 10\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "3CHQ7GWd6CH4",
        "outputId": "2a2d1e8d-3b40-49b5-873a-52963cbf6e4f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "#Initializing the model and the estimator\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 30, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb1f192a780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 10, '_save_checkpoints_steps': 30, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fb1f192a780>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mn8qUu326CH8",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Voutrvsq6CH_",
        "outputId": "3973ac3d-c985-4caa-d584-853c3c5e1b29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "#Training the model\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Skipping training since max_steps has already saved.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:00:00.009790\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "nDwzMMR-6CIC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 972
        },
        "outputId": "ff3047f7-56f0-40f7-c461-0974aec792e1"
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-fc10609493c0>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-fc10609493c0>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-03-15T22:05:05Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-03-15T22:05:05Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-03-15-22:05:42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-03-15-22:05:42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 400: eval_accuracy = 0.328125, false_negatives = 37.0, false_positives = 3.0, global_step = 400, loss = 2.5655584, true_negatives = 12.0, true_positives = 12.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 400: eval_accuracy = 0.328125, false_negatives = 37.0, false_positives = 3.0, global_step = 400, loss = 2.5655584, true_negatives = 12.0, true_positives = 12.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: model/model.ckpt-400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 400: model/model.ckpt-400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.328125,\n",
              " 'false_negatives': 37.0,\n",
              " 'false_positives': 3.0,\n",
              " 'global_step': 400,\n",
              " 'loss': 2.5655584,\n",
              " 'true_negatives': 12.0,\n",
              " 'true_positives': 12.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_V2gLhrx6CIF",
        "colab": {}
      },
      "source": [
        "# A method to get predictions\n",
        "def getPrediction(in_sentences):\n",
        "  # Transforming the test data into BERT accepted form\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
        "  \n",
        "  # Creating input features for Test data\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "  # Predicting the classes \n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], prediction['labels']) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ys7myfKF6CIJ",
        "outputId": "4920c614-5a67-4bf3-a6f8-53bc9cc3740f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pred_sentences = list(test['Contents'])\n",
        "predictions = getPrediction(pred_sentences)\n",
        "predictions[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 80\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ dr ##th ##oma ##sw ##hit ##e @ mathews _ archery glad you clarified what that pipe was . originally thought you accidental ##y left your va ##pe stick in the picture [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ dr ##th ##oma ##sw ##hit ##e @ mathews _ archery glad you clarified what that pipe was . originally thought you accidental ##y left your va ##pe stick in the picture [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2852 2705 9626 26760 16584 2063 1030 23287 1035 21383 5580 2017 20485 2054 2008 8667 2001 1012 2761 2245 2017 17128 2100 2187 2115 12436 5051 6293 1999 1996 3861 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2852 2705 9626 26760 16584 2063 1030 23287 1035 21383 5580 2017 20485 2054 2008 8667 2001 1012 2761 2245 2017 17128 2100 2187 2115 12436 5051 6293 1999 1996 3861 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ bad _ bitch ##ski i honestly love my ju ##ul . the thought of having a ci ##g now makes me feel gross [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ bad _ bitch ##ski i honestly love my ju ##ul . the thought of having a ci ##g now makes me feel gross [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2919 1035 7743 5488 1045 9826 2293 2026 18414 5313 1012 1996 2245 1997 2383 1037 25022 2290 2085 3084 2033 2514 7977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 2919 1035 7743 5488 1045 9826 2293 2026 18414 5313 1012 1996 2245 1997 2383 1037 25022 2290 2085 3084 2033 2514 7977 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ ox ##ym ##me : om ##gg ##g i felt this ; im ##a still smoke the hook ##ah if it â€™ s not mint , i â€™ m just gonna say â€œ you should â€™ ve got mint â€ the whole time [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ ox ##ym ##me : om ##gg ##g i felt this ; im ##a still smoke the hook ##ah if it â€™ s not mint , i â€™ m just gonna say â€œ you should â€™ ve got mint â€ the whole time [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 23060 24335 4168 1024 18168 13871 2290 1045 2371 2023 1025 10047 2050 2145 5610 1996 8103 4430 2065 2009 1521 1055 2025 12927 1010 1045 1521 1049 2074 6069 2360 1523 2017 2323 1521 2310 2288 12927 1524 1996 2878 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 23060 24335 4168 1024 18168 13871 2290 1045 2371 2023 1025 10047 2050 2145 5610 1996 8103 4430 2065 2009 1521 1055 2025 12927 1010 1045 1521 1049 2074 6069 2360 1523 2017 2323 1521 2310 2288 12927 1524 1996 2878 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] so it is now illegal to va ##pe in san francisco . it ' s still 100 % legal to shit on the street in san francisco though . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] so it is now illegal to va ##pe in san francisco . it ' s still 100 % legal to shit on the street in san francisco though . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2061 2009 2003 2085 6206 2000 12436 5051 1999 2624 3799 1012 2009 1005 1055 2145 2531 1003 3423 2000 4485 2006 1996 2395 1999 2624 3799 2295 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2061 2009 2003 2085 6206 2000 12436 5051 1999 2624 3799 1012 2009 1005 1055 2145 2531 1003 3423 2000 4485 2006 1996 2395 1999 2624 3799 2295 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ sy ##lves ##ss ##ter ##r she threw up va ##pe life for the gang . [UNK] , they gonna box the whip and have sex [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ sy ##lves ##ss ##ter ##r she threw up va ##pe life for the gang . [UNK] , they gonna box the whip and have sex [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 25353 20899 4757 3334 2099 2016 4711 2039 12436 5051 2166 2005 1996 6080 1012 100 1010 2027 6069 3482 1996 11473 1998 2031 3348 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 25353 20899 4757 3334 2099 2016 4711 2039 12436 5051 2166 2005 1996 6080 1012 100 1010 2027 6069 3482 1996 11473 1998 2031 3348 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-400\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-400\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('@DrThomasWhite @Mathews_Archery Glad you clarified what that pipe was. Originally thought you accidentaly left your vape stick in the picture ğŸ˜‚',\n",
              " array([-0.7169307, -1.4463801, -1.2861578], dtype=float32),\n",
              " 0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "t_KyOb_26CIM",
        "colab": {}
      },
      "source": [
        "enc_labels = []\n",
        "texts = []\n",
        "for i in range(len(predictions)):\n",
        "  enc_labels.append(label_list[predictions[i][2]])\n",
        "  texts.append(predictions[i][0].replace('\\n', ' '))\n",
        "    \n",
        "import numpy as np\n",
        "table = pd.DataFrame(np.array([texts, enc_labels, test['Opinion']]).T, columns = ['Text', 'Label', 'True'])\n",
        "table.to_csv('submission_bert.csv', sep = '\\n', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f1WbvhQU2LXu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a81f73b7-acee-4e3c-afc7-238a1bde2177"
      },
      "source": [
        "table"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Text</th>\n",
              "      <th>Label</th>\n",
              "      <th>True</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@DrThomasWhite @Mathews_Archery Glad you clari...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@bad_bitchski I honestly love my juul. The tho...</td>\n",
              "      <td>-1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>QT @oxymme: Omggg I felt this ; ima still smok...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>So it is now illegal to vape in San Francisco....</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@Sylvesssterr She threw up Vape Life for the G...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>@MenlionD U so fucking dirty for that lmao. Va...</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>Lol I think about vaping again all the time bu...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>Hookah on the balcony</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>QT @AddieMarieP: Me tries to hangout with some...</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>QT @SwiftOnSecurity: i was *not* on this call....</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>80 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 Text Label True\n",
              "0   @DrThomasWhite @Mathews_Archery Glad you clari...    -1    0\n",
              "1   @bad_bitchski I honestly love my juul. The tho...    -1    1\n",
              "2   QT @oxymme: Omggg I felt this ; ima still smok...    -1    0\n",
              "3   So it is now illegal to vape in San Francisco....     0    1\n",
              "4   @Sylvesssterr She threw up Vape Life for the G...    -1    0\n",
              "..                                                ...   ...  ...\n",
              "75  @MenlionD U so fucking dirty for that lmao. Va...    -1   -1\n",
              "76  Lol I think about vaping again all the time bu...    -1    0\n",
              "77                              Hookah on the balcony    -1    0\n",
              "78  QT @AddieMarieP: Me tries to hangout with some...    -1    0\n",
              "79  QT @SwiftOnSecurity: i was *not* on this call....    -1    0\n",
              "\n",
              "[80 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UlkqF2LO6CIP",
        "outputId": "b1bf7df8-4aca-46c0-97b3-d4b31c7e4b86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!cat submission_bert.csv"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text\n",
            "Label\n",
            "True\n",
            "@DrThomasWhite @Mathews_Archery Glad you clarified what that pipe was. Originally thought you accidentaly left your vape stick in the picture ğŸ˜‚\n",
            "-1\n",
            "0\n",
            "@bad_bitchski I honestly love my juul. The thought of having a cig now makes me feel gross\n",
            "-1\n",
            "1\n",
            "QT @oxymme: Omggg I felt this ; ima still smoke the hookah if itâ€™s not mint, Iâ€™m just gonna say â€œyou shouldâ€™ve got mintâ€ the whole time\n",
            "-1\n",
            "0\n",
            "So it is now illegal to vape in San Francisco. It's still 100% legal to shit on the street in San Francisco though.\n",
            "0\n",
            "1\n",
            "@Sylvesssterr She threw up Vape Life for the Gang. ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£ğŸ¤£, they gonna box the whip and have sex ğŸ¤£ğŸ˜‚\n",
            "-1\n",
            "0\n",
            "2019 is so fucked. The earth is dying, im in kuwait, OJ is on twitter, my mom owns a juul, whataburger gettin pimped out, schlitterbahn gone, can the simulation cut me a fucKING BREAK PLEASE\n",
            "-1\n",
            "-1\n",
            "that juul buzz be hittin my feet more than anything no cap\n",
            "0\n",
            "0\n",
            "QT @NessaTabasco: ğŸ¤¢ğŸ¤¢ ; Son how did i lose my juul last night\n",
            "1\n",
            "0\n",
            "Anyone at #Bugcon2019 have a vape pen charger?! @bugmanetv\n",
            "0\n",
            "0\n",
            "@meetdosist @ShopMedMen I tried the Calm first as I have some lung damage from lupus and wasn't sure I'd be able to vape successfully. Now that I know I can, I plan to go back for the relief one for bedtime use. The MedMen rep was really helpful. PS: my cat LOVES the smell. LOL\n",
            "-1\n",
            "1\n",
            "@HillaryClinton Anyone here into guns? Vaping?\n",
            "0\n",
            "0\n",
            "Just got my suegra to try my vape. She doesnâ€™t know it but sheâ€™s about to get plastered.\n",
            "1\n",
            "0\n",
            "@NewsBreaking 'The womanâ€™s boyfriend told investigators she used a marijuana vaping pen and had been to the ER three weeks before she died because of a chest infection.' So really it was a combo of tainted GMO type vape juice/or pen and her chest infection.\n",
            "-1\n",
            "0\n",
            "I just got IDâ€™d for a juul charger like ?? Make sure Iâ€™m 18 years old so I can buy a charger plz\n",
            "-1\n",
            "0\n",
            "me: *doesnâ€™t eat a meal until 5pm* also me: *chain smokes juul and black iced coffees* also also me: *is slut* also also also me: â€œwhy do i keep getting sick??â€\n",
            "-1\n",
            "0\n",
            "@BriannaMonetB What kind of hookah Hoe are you ğŸ¤¦ğŸ»â€â™€ï¸\n",
            "0\n",
            "0\n",
            "In the middle of a first degree murder sentencing (yes I lost) and my mother is texting me about the dangers of vaping and friggin popcorn lung. Need to work on boundaries.\n",
            "-1\n",
            "0\n",
            "@TREESVlNYL *blows vape smoke trying to be cool* *brother ruins it by blowing it away* â€œADAMâ€\n",
            "1\n",
            "0\n",
            "QT @truthorange: Your ads make me wanna start vaping out of spite ; Let's just say it's a lot harder to keep that inside stuff inside of you when you vape.\n",
            "-1\n",
            "0\n",
            "QT @donnicholass: ğŸ—£ğŸ—£ğŸ—£ğŸ—£ğŸ—£ ; â€¢ DAY PARTY AT ZONA â€¢ NO COVER | $100 REG BOTTLES | $15 HOOKAH | $5 REFILLS | OUTSIDE PATIO | KITCHEN AVAILABLE ALL DAY! FMI CONTACT ME! Sounds by @DJDymand x @Deeejaybebo ğŸ™ŒğŸ¾\n",
            "-1\n",
            "0\n",
            "@_jhezze @ExchangeLA Be careful tho. Because one time I was allowed in with my hat and vape. Next time no hat and no vape was allowed.\n",
            "-1\n",
            "0\n",
            "@axios It's all those damn vapes and juuls. LOL\n",
            "-1\n",
            "0\n",
            "@Sun_Daze_11 I wish someone backed me up when I tried to call someone out about vaping in my section last season. The usher said they didnâ€™t see it.\n",
            "-1\n",
            "-1\n",
            "My juul friends.. whereâ€™s the cheapest place to buy a juul. I lost mine and Iâ€™m not trying to be dumb and spend $75 on one again from a vape shop.\n",
            "0\n",
            "1\n",
            "Anybody ever use coconut water in they hookah ?\n",
            "-1\n",
            "0\n",
            "People are fucking fiends now days, i could put a hit on someone for a Juul pod\n",
            "-1\n",
            "0\n",
            "Carts/vapes are trash. Iâ€™d rather just roll up\n",
            "-1\n",
            "-1\n",
            "hey guys whats a way to stop cravings instead of using juul\n",
            "0\n",
            "0\n",
            "Anywhere you work theres always one vaping coworker that dyes their hair\n",
            "-1\n",
            "0\n",
            "QT @CoachCookCHS: #Preach. ; It blows my mind the amount of young student athletes that are vaping. That stuff ruins an athleteâ€™s hard work. It destroys their stamina. Athletes, you do it because itâ€™s cool? You know what else is cool? Being able to play 4 quarters of a game and lead your team to a win.\n",
            "-1\n",
            "-1\n",
            "They should replace Chuck Todd on Meet the Press with a sweating mason jar of hot dog-flavored vape juice\n",
            "-1\n",
            "0\n",
            "All she do is smoke hookah ğŸ˜©ğŸ˜©\n",
            "-1\n",
            "0\n",
            "@afrozekbeshir really @â€˜ing everyone with a juul broğŸ˜‚\n",
            "-1\n",
            "0\n",
            "My bed is calling me... this rain not it lol I wanted hookah or a drink but fuck it\n",
            "-1\n",
            "0\n",
            "I have saved a shit ton of money already switching to a Juul and also I donâ€™t reek of cigarettes. Iâ€™ve had 2 cigarettes in the past 4 days and the week before it took me an entire week to smoke one pack. daddy is living.\n",
            "-1\n",
            "1\n",
            "@castello2 @SuckMyMod @featherbear15 Before vaping was banned in my building though, I thought the ban was silly. I started reading because of that and changed my mind. Still willing to read, but it's hard for me to dismiss the sources I already mentioned.\n",
            "-1\n",
            "-1\n",
            "i need mcdonaldâ€™s and garlic bread and juul pods fuck\n",
            "-1\n",
            "0\n",
            "What is the point of hookah fr ?\n",
            "-1\n",
            "0\n",
            "@_paigesmith13 you act like im not gonna pass my juul down through the generations...\n",
            "-1\n",
            "0\n",
            "good hookah lounges in atlanta?\n",
            "-1\n",
            "0\n",
            "I feel like my juul is more addicting than cigarettes ever were. But idgaf cuz itâ€™s under half the cost of smoking and doesnâ€™t kill me!!!\n",
            "-1\n",
            "1\n",
            "Sex is great and all but have yâ€™all ever hit a juul pod when youâ€™re not used to high nicotine ğŸ‘€\n",
            "-1\n",
            "1\n",
            "So tonight at work a coworker stole my vape mod. That thing was over $100... Iâ€™m so disappointed in humans.\n",
            "0\n",
            "0\n",
            "Went to get coffee with my dad this morning. I talked him into buying a juul\n",
            "-1\n",
            "0\n",
            "@lethargicwaldo @cincynancy If you put your ear up to the can and are really silent, you can hear the Juul hit Kreygasm\n",
            "-1\n",
            "0\n",
            "Before hand I gave her a sweet smile but I got a b- itch face & google eyes in return. I kept smiling & brushed it off. Afterwards she comes army marching after me as I was vaping outside. Human behavior # 101 â€œarmy marchâ€ walking is a form of aggression.\n",
            "-1\n",
            "0\n",
            "The California Democratic Convention is sponsored by Uber, Visa, Juul, Fox, and AirBnB. WTAF? #CADem2019\n",
            "-1\n",
            "-1\n",
            "@BearlyFit @MercanthonyTV @FaZeClan @ChampionUSA @Banks @enolagayepyro damn bro what vape you got\n",
            "-1\n",
            "0\n",
            "@InsidePMI @BBCNews @sfgov What percentage of former cigarette smokers who become e-cigarette smokers eventually quit smoking entirely? What percentage revert back or become dual users?\n",
            "0\n",
            "0\n",
            "QT @_anettt_: Anet after taking 5 hits ; I think Iâ€™ve had enough hookah for the rest of my life\n",
            "-1\n",
            "0\n",
            "Im wylin if I propose to the school that I want to do a presentation about Hookah Negligence ?\n",
            "-1\n",
            "-1\n",
            "@stelIhudg you have a juul addiction & i am glad i donâ€™t have a juul addiction ğŸ˜€\n",
            "-1\n",
            "-1\n",
            "QT @scottbudman: WTF San Francisco? You fascist demagogues just might wanna do bans on feces, urine, hypodermic needles & typhus in the streets. ; The first major city in the country to ban the sale of electronic cigarettes, San Francisco, is the home of Juul. SF also recently approved a ban on the sale of flavored tobacco and a tax on sugar-sweetened drinks.\n",
            "0\n",
            "0\n",
            "@PKBohan Coffee and my vape\n",
            "0\n",
            "0\n",
            "You ever hit the hookah so hard you choke\n",
            "1\n",
            "0\n",
            "Really wanna go smoke some hookah\n",
            "-1\n",
            "0\n",
            "if i had all the money back that iâ€™ve spent on juul pods iâ€™d be papered up ğŸ˜¶\n",
            "-1\n",
            "0\n",
            "this guy just snapped me a video of dank vapes saying â€œlet me take you on a date and iâ€™ll give you a cartâ€ LOL â€œpesticides and dinner? ğŸ™ˆâ€\n",
            "-1\n",
            "-1\n",
            "why any of y'all vape when it's probably killing you is beyond me. I'll only fill my lungs with what god intended me to: latex paint and oxygen ğŸ‘‹ğŸ‘‹ğŸ‘‹\n",
            "-1\n",
            "-1\n",
            "QT @FreshOj24: LMFAOOOOOOOOOO Im glad you know ; Dominican niggas from DR donâ€™t know how to pass the hookah.\n",
            "-1\n",
            "0\n",
            "I hit the juul and i cant feel my feet rn ğŸ˜‚\n",
            "0\n",
            "0\n",
            "@MakinnPlays Well I mean it is a vape pen just with thc oil so itâ€™s like any other vape that can cause respiratory issues.... but I need more research on â€œmarijuana overdoseâ€ is what Iâ€™m saying lmao\n",
            "-1\n",
            "-1\n",
            "hookah and drinks errday\n",
            "-1\n",
            "0\n",
            "@amberbloedel Juul has been 21 and up for quite some time now.... itâ€™s their policy if a shoo is caught selling to minors they wonâ€™t distribute to them anymore. Sept. All of Texas will be Tobacco 21+, but vapes will be 18+ unless the company policy is different\n",
            "0\n",
            "-1\n",
            "I might be stupid but Iâ€™m not stupid enough to own a juul\n",
            "-1\n",
            "-1\n",
            "Forever losing my juul wow\n",
            "-1\n",
            "0\n",
            "@BRWN_EYEGURL It really looks nice . I love it down there too!!!! Lmaooo at hookah\n",
            "-1\n",
            "0\n",
            "Iâ€™m gonna have to stick up on Juul pods before I go back to California Iâ€™m 20 but the smoking age is 21 oof\n",
            "-1\n",
            "1\n",
            "All this talk about banning Juul while cigarettes are still legalğŸ˜·\n",
            "-1\n",
            "1\n",
            "Broke my vape pen at work ... but itâ€™s still hitting ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­ğŸ˜­\n",
            "-1\n",
            "0\n",
            "@_Simbasworld I can't believe in this day and age people are still smoking cancer sticks when they could be smoking or vaping trees ğŸ¤·â€â™€ï¸\n",
            "-1\n",
            "1\n",
            "@aptly_engineerd first there was juul now there is pussay, the only vape stick made with authentic vaginal mucus it will get you On\n",
            "-1\n",
            "1\n",
            "@geekyJustinLee Top 5 is pretty generous. Though I'm definitely above the dude whose emails I keep getting. He orders SO MUCH VAPE JUICE. When he's not in court-ordered drug therapy.\n",
            "0\n",
            "0\n",
            "thereâ€™s nothing better than taking a crisp hit of my vape early in the morning ğŸ¤£\n",
            "-1\n",
            "0\n",
            "can someone explain what hookah is for me\n",
            "0\n",
            "0\n",
            "@MenlionD U so fucking dirty for that lmao. Vaping is nasty and the loads of nicotine in it. You should try a wax pen next time . The stuff is weed rolled up in a pen.\n",
            "-1\n",
            "-1\n",
            "Lol I think about vaping again all the time but I know Iâ€™m not financially stable enough to be addicted to nicotine.ğŸ¤¦ğŸ¾â€â™‚ï¸ğŸ˜­\n",
            "-1\n",
            "0\n",
            "Hookah on the balcony\n",
            "-1\n",
            "0\n",
            "QT @AddieMarieP: Me tries to hangout with someone... Skinny girl with a nice smile: Iâ€™ve got my juul Me: ; Fucking cunt\n",
            "-1\n",
            "0\n",
            "QT @SwiftOnSecurity: i was *not* on this call.... ; On a 40-person call and it sounded like someone forgot mute and took a monster bong hit. Weâ€™ll just go with hookah enthusiast...\n",
            "-1\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Q0odZgLfCVH6"
      },
      "source": [
        "**Not effective... maybe data is too limited** "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "g0qVTJBv6CIT",
        "colab": {}
      },
      "source": [
        "# The END"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}