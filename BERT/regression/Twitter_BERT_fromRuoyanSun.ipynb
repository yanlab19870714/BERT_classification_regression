{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_BERT_fromRuoyanSun.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "_-K-NjnNWG2F",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "ef54e5c3-1958-47b6-96c7-29d7f57f9d90"
      },
      "source": [
        "%%javascript\n",
        "IPython.notebook.clear_all_output();"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "IPython.notebook.clear_all_output();"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LyCkMO-nDU1m",
        "outputId": "b6b53ea6-36ba-4da2-c33c-0578f749cd7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "#Installing BERT module\n",
        "!pip install bert-tensorflow"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting bert-tensorflow\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a6/66/7eb4e8b6ea35b7cc54c322c816f976167a43019750279a8473d355800a93/bert_tensorflow-1.0.1-py2.py3-none-any.whl (67kB)\n",
            "\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñâ                           | 10kB 19.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñä                      | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñã                 | 30kB 2.5MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñç            | 40kB 1.6MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñé       | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñè  | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 71kB 2.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from bert-tensorflow) (1.12.0)\n",
            "Installing collected packages: bert-tensorflow\n",
            "Successfully installed bert-tensorflow-1.0.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LNmJemTrDb4P",
        "colab": {}
      },
      "source": [
        "content = 'Contents\\tOpinion\\n\"Alright guys, juul break!\" Thanks, Mom!!\\t0\\nDoing hookah alone makes me a crackhead?\\t0\\n@bootyfinesserv3 Hookah is legit banned in this country I don‚Äôt even know how they do it lol\\t1\\nI need to go get coals for my hookah. üò© I ran out!\\t0\\nCastro exempted vaping from the HUD smoking ban, for which I am grateful.\\t1\\nLuschek stops in to talk to Gloria and sneak a few hits from his vape. She reminds him that his selfishness and apathy directly added to her sentence and cost Doggett her life. #OrangeIsTheNewBlack #OrangeForever\\t0\\nI haven‚Äôt consumed alcohol or hookah in almost 3 days üôÑüôÑüôÑüôÑ this ain‚Äôt it\\t1\\nMom and pop vape shop: Family Juuls.\\t0\\n@mikemcgowow Yeah having a partner in that shit is wicked helpful. I‚Äôll just keep rage throwing my juul into a dumpster until it works\\t0\\nI need my own hookah.\\t1\\n@dannycarlson02 protect my right to juul\\t1\\ngoing have me a drink and puff me some hookah\\t0\\nHe put Essentia in the hookah üòÇ is that‚Äôs not love I don‚Äôt know what is\\t0\\nnew vape üòÅüòçüòã\\t1\\nyang better hit a fuckin vape on stage I swear to got\\t0\\n@_paigesmith13 you act like im not gonna pass my juul down through the generations...\\t0\\n@chasssjanine I haven‚Äôt bought my vape yet though :/\\t0\\nVape rig that looks like an AirPod case‚Ñ¢\\t0\\nQT @BFBIV: update: I found it outside, cleaned her up now shes good as new. üëçüèº ; cant find my juul, panic attack ahead\\t0\\nCan somebody send a juul to Mexico please\\t0\\nBroke my phone so I have to go get a new one, popped my tire, lost my vape in a field, lost my charger, cut my body all up because I fell on a rock, called many people I shouldn‚Äôt have, lost my clothes.. all last night. Don‚Äôt drink\\t0\\n@AlanciaLynette Dawghouse I bet, some at the hookah lounge too?\\t0\\n@mattPFV Vape Nation Man\\t1\\nQT @Sizzilin_Stew: This is what they‚Äôve been waiting for ; Boys Daddy is OFF the JuuL and onto the cigarettes\\t0\\nsome of you have never experienced getting anxiety ab asking if u can hit ur friends juul and its SHOWS.\\t0\\n@BretWeinstein You mean vaping Roundup is bad for me? Thanks California!\\t0\\n@jordaanblok I\\'m the discreet juul (What top are you wearing?)\\t0\\nQT @CDCTobaccoFree: Totally get the campaign against combustible and chewable tobacco but vape has been a good middle ground for recovering smokers. That kids use them is an issue of poor parenting. ; E-cigarettes contain nicotine, which can impact learning and memory. Learn the health risks for your young patients.\\t1\\nForever losing my juul wow\\t0\\nimagine not being able to go 5 min without ripping a juul and spending mad money on pods ,,,, couldn‚Äôt be me sis ü§ß\\t0\\nI can‚Äôt tell if I‚Äôm still in Brooklyn ... I‚Äôm walking up franklin and niggas smoking hookah on the corner\\t0\\nQT @elfishh: 1. Vape 2. World of Rocks punch card 3. Perfume/cologne samples 4. Aveeno unscented lotion 5. OG Hot Topic ‚Äúfriends with benefit‚Äù card ; new personality quiz: describe yourself using 5 things that are probably in your purse/backpack/whatever at any given moment\\t0\\nwent to hit my vape but instead it was my water bottle so now i‚Äôm drowning and stupid\\t1\\n@philterlabs @WeedFeed @TheWeedTube1 A lot of effort to hide the Smell . Vape pens almost no Oder\\t0\\n@NewsBreaking \\'The woman‚Äôs boyfriend told investigators she used a marijuana vaping pen and had been to the ER three weeks before she died because of a chest infection.\\' So really it was a combo of tainted GMO type vape juice/or pen and her chest infection.\\t0\\n@castello2 @SuckMyMod @featherbear15 Before vaping was banned in my building though, I thought the ban was silly. I started reading because of that and changed my mind. Still willing to read, but it\\'s hard for me to dismiss the sources I already mentioned.\\t-1\\ni lost my fucking juul, my nail is messed up, its hot, AND im broke as fuck now so happy friday to me lol\\t0\\nI think I lost my juul and i‚Äôm upset\\t0\\n@Simonee_99 ian never smokin on hookah again\\t-1\\n@tripndie me every time i juul\\t0\\nguys im coming at u with very sad news. i lost my jesus juul yesterday and i wanted everyone to know i will be mourning for a while. would appreciate some time to heal. thank u have a blessed day\\t0\\nWhen are they gonna come out with a juul emoji tho\\t0\\nupdate: I figured out how to get my vape mixture 2:1 cbd to juice ratio, now I‚Äôm exxxtra chill\\t1\\nI wanna b as passionate about something like people that stay up to date on the latest vape tech and shit\\t0\\nFuck a juul Im purchasing a vape lol\\t1\\nSex is great and all but have y‚Äôall ever hit a juul pod when you‚Äôre not used to high nicotine üëÄ\\t1\\nI want to go to the hookah bar\\t0\\nQT @_kissmycass: We destroyed the planet with cigs and now we‚Äôre going to do it with juuls? Y‚Äôall are trash ; Idk who needs to hear this but... STOP THROWING YOUR EMPTY JUUL PODS ON THE FLOOR It is littering. They are thick hard plastic w chemicals and are the perfect size for animals to eat\\t-1\\nAll she do is smoke hookah üò©üò©\\t0\\nYou ever hit the hookah so hard you choke\\t0\\ni need mcdonald‚Äôs and garlic bread and juul pods fuck\\t0\\nVaping outside the Olive Garden like true American white trash\\t0\\n@SwaggerSouls Swags your gonna died with the next 2 weeks an kill everyone in that house for your juul In other words.. You fucking weak cunt give up now before its too late\\t-1\\nI‚Äôm going to ask again do people inhale hookah?\\t0\\n@TimRunsHisMouth And harbor criminals, legalize marijuana and hand out hypodermic needles but don‚Äôt you dare Juul.\\t1\\nImagine being an adult using a juul to quit smoking, and you really like mango pods, but a bunch of nicotine addicted 16 year old got your shit taken.\\t1\\nQT @CoachCookCHS: #Preach. ; It blows my mind the amount of young student athletes that are vaping. That stuff ruins an athlete‚Äôs hard work. It destroys their stamina. Athletes, you do it because it‚Äôs cool? You know what else is cool? Being able to play 4 quarters of a game and lead your team to a win.\\t-1\\n@PKBohan Coffee and my vape\\t0\\nQT @CAVBERNAH: ü§£ü§£ü§£ü§£ü§£ ; Y‚Äôall not tired of blowing hookah smoke into your phone via snap!? Jeez I‚Äôm tiiiiiiide of seeing it\\t-1\\nI‚Äôve been cleaning/doing chores, listening to music all day and keep taking breaks to tweet and vape my cbd lmaooo\\t0\\ncan i hit someone‚Äôs juul\\t0\\n@twentyfourzz I bought a juul charger today ($10.95)\\t0\\n@AW_YouMad Cuz I can‚Äôt do the hookah fr\\t0\\n‚ÄúDoes anyone have a fucking juul?‚Äô‚Äù @THEnolanhenly Also ‚Äúbust down thotiana‚Äù in the stockyards @Carson_Reed10\\t0\\n@VapinSquirrel @jsummers71 #vape #vapingsaveslives #vapefam Well put Ivanna üëàüëèüëè\\t1\\n@glorianna21 Not anymore :/ now it‚Äôs bubba vape\\t0\\n@kittypurrzog I think the headline should be \"SF becomes the first US city to create a e-cig black market\"\\t0\\nI need to be completely naked , stomach on E , and sleep for like 6 hours straight and then wake up to being held and cuddled. And then make some lasagna or Meatballs. A little vape üí® wouldn‚Äôt be bad either lmfao .\\t0\\nQT @SwiftOnSecurity: i was *not* on this call.... ; On a 40-person call and it sounded like someone forgot mute and took a monster bong hit. We‚Äôll just go with hookah enthusiast...\\t0\\nif i had all the money back that i‚Äôve spent on juul pods i‚Äôd be papered up üò∂\\t0\\n@thisisbrookeb we‚Äôre literally vape hot boxing your car\\t0\\nFor every gift giving holiday I get asked if I‚Äôd like Juul Pods.. is this a problem?!\\t0\\n@lilfryh Didn‚Äôt say mango juul pods\\t0\\n@TweetsbyMontyy Hookah smoke\\t0\\nIf you juul, I will think lesser of you and make no apologies\\t-1\\n*charges my vape pen in the school library computers*\\t0\\nThey should replace Chuck Todd on Meet the Press with a sweating mason jar of hot dog-flavored vape juice\\t0\\nI brought a vape today. It was the most impulsive of impulse buys\\t0\\nReal friends let you borrow their juul charger @sav_hartmann\\t0\\n@yessiebabyyy Juul‚Äôs are horrible, go to a vape shop and get a real mod\\t1\\nIon smoke vapes that aint come from a dispensary\\t0\\nOoooo them post shower juul rips, shit hits diffffferentttt\\t0\\ni‚Äôm in naperville with no juul charger .. who got me /:\\t0\\n@antihannaszn Them shits r like craxk tho fr they hit better than most Vapes\\t1\\nFinally 21‚ÄºÔ∏èüî•ü§Ø Now I can finally go to a Queens hookah lounge üå∂üôáüèΩ\\u200d‚ôÇÔ∏è I hope it‚Äôs fun üò≥üôèüèΩ\\t0\\nJust so everyones up to date, my juul fell 38 floors and still works\\t1\\nhad juul and a bang for breakfast ü§™‚úåüèº\\t1\\nme a year ago: we GET IT you VAPE me now: *buys a vape pen*\\t1\\nToday I bought juul pods good big\\t0\\nIn Canada they call creme brulee juul pods just \"vanilla.\" Truly the land time forgot.\\t0\\nmy friend told me they were going to buy me a juul for my birthdayüò≥\\t0\\nIm wylin if I propose to the school that I want to do a presentation about Hookah Negligence ?\\t-1\\n@johnaarellano I found your juul\\t0\\nQT @donnicholass: üó£üó£üó£üó£üó£ ; ‚Ä¢ DAY PARTY AT ZONA ‚Ä¢ NO COVER | $100 REG BOTTLES | $15 HOOKAH | $5 REFILLS | OUTSIDE PATIO | KITCHEN AVAILABLE ALL DAY! FMI CONTACT ME! Sounds by @DJDymand x @Deeejaybebo üôåüèæ\\t0\\n@JenaLuckman Probably have all the juul pods but no chargers... it is hell after all\\t0\\nNo one: Me holding out a vape pen: Moon prism power, make up! üíñüåô‚ú®\\t0\\nhey guys whats a way to stop cravings instead of using juul\\t0\\n@afairyhoe Legit just switch to the gum or a vape already. Why? Because it\\'s healthier. Your literally sucking up tar smoke ontop of what your body is craving.\\t1\\nAnyone need some vape juice? I got a Fizzy Lemonade that I only used once. Not a big fan of it. 50 mg for $20.\\t0\\nme: *doesn‚Äôt eat a meal until 5pm* also me: *chain smokes juul and black iced coffees* also also me: *is slut* also also also me: ‚Äúwhy do i keep getting sick??‚Äù\\t0\\nWhy can‚Äôt I ping my JUUL\\t0\\nWash your hands before touching your face and drink plenty of water. And lay off that hookah\\t-1\\nI just got ID‚Äôd for a juul charger like ?? Make sure I‚Äôm 18 years old so I can buy a charger plz\\t0\\n@DrThomasWhite @Mathews_Archery Glad you clarified what that pipe was. Originally thought you accidentaly left your vape stick in the picture üòÇ\\t0\\nQT @Mhern23: Why are you me lmao ; My phone feels so much skinnier without my juul holder.\\t0\\ncan someone explain what hookah is for me\\t0\\n50% off hookah @ Adolfo‚Äôs tonight word around town\\t0\\n@XanderSX14 ‚ÄúThey be smacking tho‚Äù DANK VAPES (Fuck that foo juice) fucken dollar tree as beaners lmao\\t0\\nSo it is now illegal to vape in San Francisco. It\\'s still 100% legal to shit on the street in San Francisco though.\\t1\\nIt‚Äôs funny cause the predominantly black high schools in Staten Island have metal detectors and all that cause they‚Äôre ‚Äúdangerous‚Äù meanwhile my cousin is 12 in a ‚Äúgood‚Äù public school and there‚Äôs a white boy in his class that‚Äôs been trying to sell him juul pods. 12 YEARS OLD.\\t-1\\nim finna buy a hookah\\t0\\n@thedrunkpenguin I know a few that have quit using vaping they say the trick is to reduce the nicotine over time. I just never really enjoyed it that much, could never seem to find one that replicated actual cigarettes.\\t-1\\nNigga said ‚Äúthe port taste better that the hookah ‚Äú üò≠üò≠üò≠\\t0\\nYour mcm thinks Juul is a beautiful baby name for his next daughter\\t0\\nStill can‚Äôt believe my grandma threwmy vape awayüòÇ\\t0\\n@bad_bitchski I honestly love my juul. The thought of having a cig now makes me feel gross\\t1\\nQT @KaylaaaasWorld: It made sense üòÇüíÄ ; @teyanapryor_ : I think I need to stand up, so the hookah can flow this way *points from head to toe* üòÇüò≠\\t0\\nQT @oxymme: Omggg I felt this ; ima still smoke the hookah if it‚Äôs not mint, I‚Äôm just gonna say ‚Äúyou should‚Äôve got mint‚Äù the whole time\\t0\\nPSA YET AGAIN ON THE CARTS. Not only are the DANK VAPES being copied but now KING PENS are too! Know wtf you are buying and be safe ‚ù§Ô∏è\\t0\\nAnyone at #Bugcon2019 have a vape pen charger?! @bugmanetv\\t0\\n@axios It\\'s all those damn vapes and juuls. LOL\\t0\\nJust got my suegra to try my vape. She doesn‚Äôt know it but she‚Äôs about to get plastered.\\t0\\nsome 6‚Äô5‚Äù dude with a juul and a glass of beer is standing next to me and i‚Äôm already annoyed. he‚Äôs come so close to elbowing my face\\t0\\ntalkin bout ‚ÄòiLl nEvEr sMoKe a CiG‚Äô but use a juul. whole ass FOOL ü§£\\t-1\\n@idkimemotional Wow me too coffee and vape lol\\t0\\nWhere can I get a dope hookah Machine ?\\t0\\nthis guy just snapped me a video of dank vapes saying ‚Äúlet me take you on a date and i‚Äôll give you a cart‚Äù LOL ‚Äúpesticides and dinner? üôà‚Äù\\t-1\\nWOW! I just found out about juul! ü§£ü§£\\t1\\n@chelseacomics You could always try vaping? I know they make pure CBD oil for that stuff, so you‚Äôd cut down on additives. I know it‚Äôs got a douche bag rep, but honestly vaping product helps me a lot.\\t1\\nWasn\\'t paying attention while filling my top-fill vape tank and squirted an entire tanks worth of juice down the chimney.\\t0\\nMy vape isn‚Äôt charging and my juul is out. What ever did I do to deserve this shit\\t0\\nIf you see me vaping it\\'s for a solid cause, I\\'m trying hard to completely eliminate cigars cigarettes and tobacco out of my life. I hate vape but it\\'s honestly better for me than the 4 blacks I\\'d smoke a day.\\t1\\nmy little brother: you know what my favorite thing about this place is, we‚Äôre the only two people without a vape or a crop top here, except you\\t0\\nI hope y‚Äôall know that smoking hookah for even an hour is the equivalent to smoking 100+ cigarettes, but keep flexing for social media üòÇ\\t-1\\nHaving no juul pods makes me deceased\\t1\\n@thattxkid @cheatham_cody ‚Äústormy do your have your juul on you?‚Äù ‚Äúcan i hit your juul?‚Äù üíÄüíÄüíÄüíÄüíÄ\\t0\\nI need a JuuL pod. Just one single pod.\\t0\\nHookah on the balcony\\t0\\njuul pods are 21 dollars in Tampa they‚Äôre 17 in Cleveland this is sum bullshit\\t0\\nQT @BigCripnAce: Felt this ; we need more weed friendly bars i‚Äôm tryna smoke Tooka not no Hookah\\t0\\nsmoking juul at work cuz ima baaaddd person\\t0\\nAll this talk about banning Juul while cigarettes are still legalüò∑\\t1\\nIf u wanna become the next millionaire plz make a find my juul app throw me like 20% cause i gave u the idea\\t0\\ni FT my mom and we both doing the same thing.. she was smoking a cig ü§¢ ( me hookah ) and sippin\\t0\\nIt works good but I hate that it doesn‚Äôt match üôÑ I swear I‚Äôm never letting anyone borrow my vape again\\t0\\ni cannot go anywhere without losing my juul\\t0\\nYo real quick does anyone know if my FitBit can track juul rips?\\t0\\nMy kid is eleven. At his dad\\'s house, he has had weed laced chocolate chips, and he\\'s been vaping.. my ex is such a fucking tool. He thinks I\\'m the fucking dead beat when he can\\'t even pay a-fucking-ttention! I\\'ll take legal steps if it doesn\\'t stop üò°\\t-1\\n@ManguPena And a hookah installed with a long as hose and and bucket full of ice with henny\\t0\\n@MakinnPlays Well I mean it is a vape pen just with thc oil so it‚Äôs like any other vape that can cause respiratory issues.... but I need more research on ‚Äúmarijuana overdose‚Äù is what I‚Äôm saying lmao\\t-1\\nQT @scottbudman: This is great and all but like... regular tobacco still kills people and has been around for muuuuch longer. And real talk, still got addicted to that without fruit loops flavoring ü§∑üèº\\u200d‚ôÄÔ∏è ; The first major city in the country to ban the sale of electronic cigarettes, San Francisco, is the home of Juul. SF also recently approved a ban on the sale of flavored tobacco and a tax on sugar-sweetened drinks.\\t1\\n@sadsagsun Nicotine at least in their posts. I don‚Äôt like the idea of tobacco or vape (or even alcohol) companies advertising AT ALL. But I know that‚Äôs unrealistic and just my own opinion and can‚Äôt really be enforced\\t-1\\n@kahlia_miller I lose my juul literally like every day\\t0\\nI‚Äôve had the same juul pod for two days you can tell @Crow_boi hasn‚Äôt been around much ü§∑üèº\\u200d‚ôÄÔ∏èüòÇ\\t0\\nSo I took my blazer off. The Mom that claims to of worked w #JasonBateman asks me what I had for dinner. I said some zucchini & a sliver of lemon cake üç∞ The rest was meat based I believe. Idk üòê But I may be the only one on set that misses my vape üí®üòÅüé•\\t0\\nQT @rustygunter: üòÜ ; Guys that vape, do y‚Äôall shave your pussy completely or leave a landing strip?\\t0\\n@BriannaMonetB What kind of hookah Hoe are you ü§¶üèª\\u200d‚ôÄÔ∏è\\t0\\n@BearlyFit @MercanthonyTV @FaZeClan @ChampionUSA @Banks @enolagayepyro damn bro what vape you got\\t0\\nTexass vape xbox 2 #rapenotgood\\t0\\n@Sylvesssterr She threw up Vape Life for the Gang. ü§£ü§£ü§£ü§£ü§£, they gonna box the whip and have sex ü§£üòÇ\\t0\\nill quit hitting my juul when people stop aggravating the FUCK out me.\\t0\\nComing up next on CCTV\\'s public channel (Comcast8/Verizon43) 6/24/2019 3:10:04 AM: Norfolk County Prevention Coalition on Vaping May2019\\t0\\n@GroverNorquist Banning baking shoots not kill those jobs. Those jobs do not require vaping.\\t0\\n@BRWN_EYEGURL It really looks nice . I love it down there too!!!! Lmaooo at hookah\\t0\\nUGHHH if ur gonA HAVE OFFbrand juul FREAKING pods WARN A BITCH be4 I order it on FREAKING Postmates\\t0\\nMy car is full of juul pods and Taco Bell sauces\\t0\\nI Love Hookah but that shit be a bitch to clean.\\t0\\n@Hiiiiii74 @projectxpatriot @greshstart @CDCTobaccoFree Please name the ‚Äúchemicals.‚Äù Vaping 10 years and making my own eliquid for 9 of those, I‚Äôd like to compare my ingredients with what you have down\\t1\\nIf underage Juul use is such a big problem in America, why dont they just lower the legal maximum nicotine content for all E-Juices like they have in the EU? ü§¶üèΩ\\u200d‚ôÇÔ∏è Not even a 20 year cigarette smoker needs 40+ mg to make the switch to E-cigs... @JUULvapor @Surgeon_General\\t-1\\nIf cigarette companies can\\'t advertise on TV I truly believe Vape companies should be barred as well... Just because you added a battery doesn\\'t make it any less dangerous....\\t-1\\nmy cousins dad got me a vape\\t0\\n@C0urtneyg0rd0n2 bout to do the same with my juul smh\\t0\\nIn the middle of a first degree murder sentencing (yes I lost) and my mother is texting me about the dangers of vaping and friggin popcorn lung. Need to work on boundaries.\\t0\\n@isitastranger sending u virtual vape clouds\\t0\\n@_jhezze @ExchangeLA Be careful tho. Because one time I was allowed in with my hat and vape. Next time no hat and no vape was allowed.\\t0\\nMy friend couldn‚Äôt bring his vape in so now I‚Äôm alone at the dayclub who‚Äôs ready for some social anxiety tweets\\t0\\nQT @_anettt_: Anet after taking 5 hits ; I think I‚Äôve had enough hookah for the rest of my life\\t0\\nStart your week off right with 10% off all Vape Cartridges and Batteries.\\t0\\nJust saw ray walking to St. Thomas holding and smoking a whole hookah. Man it‚Äôs good to be back in Waterford\\t0\\n@InsidePMI @BBCNews @sfgov What percentage of former cigarette smokers who become e-cigarette smokers eventually quit smoking entirely? What percentage revert back or become dual users?\\t0\\n@JayPizzle88 @officialmcafee @money_alotta That‚Äôs fucking awesome. I have trouble drawing stick people and artwork I‚Äôve tried to produce on a computer involves several hours, f bombs, exhausted JUUL cartridges, and booze back when I drank and that is doing something as simple as photo shopping Johns head into a meme\\t0\\nI‚Äôve been using some version of #ecig since 2011... we‚Äôve owned a juice and boxmod company, sold it to a bigger co. I‚Äôm #burnedout with the #coils and #cotton and making or buying juice.\\t0\\nAnywhere you work theres always one vaping coworker that dyes their hair\\t0\\nI‚Äôll be at La Hookah Town on Vernor in SW Detroit tomorrow hosting my first event ü§ü Vlogging the entire night. If your free come out and support üí®‚ö°Ô∏èüñ§\\t1\\nI feel so much better since I‚Äôve been on Herbalife. & I quit smoking my Mod , I haven‚Äôt smoked in like 3 weeks, & I was vaping 3 yrs\\t-1\\n@anulikesstars LE VAPE SHOP!!!!!! I AM OBSESSED. Is it a \"le juul\"? pls say yes/ pls inquire for me\\t1\\nQT @destinnybrownn: Same ü•¥ ; I literally need to start taping my juul to my forehead bc this little hoe be hidingüò°\\t0\\nQT @_malyxo: he do be cappin for the bird ; I promise you guys kylers the sweetest little ting IN PERSON online he‚Äôs an asshole but at meets he just smiles and smokes hookah\\t0\\n@Saint_Grobian beef jerky flavored vape cartridges\\t0\\nThis hookah hitting so coo It‚Äôs crazy\\t1\\nYou ever just hit your juul upside down? Cuz same\\t0\\nCan you bring a vape pen on the plane?\\t0\\n@asvpxpatrick @faithyangelz Just vape lmao no nicotine\\t0\\n2019 is so fucked. The earth is dying, im in kuwait, OJ is on twitter, my mom owns a juul, whataburger gettin pimped out, schlitterbahn gone, can the simulation cut me a fucKING BREAK PLEASE\\t-1\\nReally wanna go smoke some hookah\\t0\\nSomeone buy this damn juul since i can‚Äôt use it anymore ‚òπÔ∏è\\t0\\nQT @ZoeyHertz: i dont have a juul but does this apply to thc pens as well? üò© ; I have been juuling for 2 years and now I have pre oral cancer. So stop juuling kids lol\\t-1\\nBold of you to assume I wanna smell your vape cloud\\t0\\nQT @truthorange: Your ads make me wanna start vaping out of spite ; Let\\'s just say it\\'s a lot harder to keep that inside stuff inside of you when you vape.\\t0\\nAustin just walked in and traded the dap pen for the juul and just dipped w out a wordüòÇüòÇüòÇ clutch\\t0\\n@DREWWESS @KHOU They are or they‚Äôre They are still breaking the law Vaping is also a health hazard.\\t-1\\nWhere y‚Äôall buy them hookah pens? I‚Äôm tryna but my bestie one.\\t0\\nQT @EwdatsGROSS: please stop i‚Äôm calling the police ; A juul My pussy ü§ù You can hit it\\t0\\n@StefanDidak That\\'s just sad. I knew that SF had a drug problem, but that\\'s just straight up absurd. All the more so that they decided a vaping ban would be beneficial, rather than tackling that!\\t1\\nQT @DylDuplechain: This right here !!! ; why you gonna waste you money on juul pods of you cant even inhale the juul?\\t1\\nQT @bshj__: Making throat cancer a social experience ; What‚Äôs the purpose of hookah??\\t-1\\n2016-18 hookah was always a motive ü§¶üèΩ\\u200d‚ôÇÔ∏è\\t0\\nIt‚Äôs always the ones with the big butts that can‚Äôt dance in the club. Para que tienen üçë, just to show off and smoke hookah. Smh ü§¶üèΩ\\u200d‚ôÇÔ∏è\\t0\\nholy shit I left my juul in my jeans when I was washing them but I saved it just in time half way through the wash. God really does exsist. SHEEEESH\\t0\\nDriving a challenger and smoking strawberry jelly donut vape juice.. hide ya girl üëÄ\\t0\\n‚Äú i don‚Äôt Juul, I don‚Äôt do cocaine but I use straws OK‚Äù\\t0\\natl done turned me to hookah thot üòÇ\\t0\\nWoke up today, drank some coffee, hit my juul, figured out that pigeon racing is a huge thing in China.. regular old Saturday..\\t0\\nI‚Äôm gonna have to stick up on Juul pods before I go back to California I‚Äôm 20 but the smoking age is 21 oof\\t1\\nI need a new data plan on my juul\\t0\\n@BLUNTxBurner420 üôåüôåüôåüôå FuCk DrInKiNg AlChoHol WhEn We CaN vApE iT!!!\\t0\\nThe family that vapes together stays together, clearly.\\t1\\n10 min into cleaning my room and I found my juul charger üíÖ\\t0\\nnothing like a post-coital juul\\t1\\nMOM DID YOU TAKE MY JUUL\\t0\\n@amberbloedel Juul has been 21 and up for quite some time now.... it‚Äôs their policy if a shoo is caught selling to minors they won‚Äôt distribute to them anymore. Sept. All of Texas will be Tobacco 21+, but vapes will be 18+ unless the company policy is different\\t-1\\nhookah >>>>\\t0\\n@Sun_Daze_11 I wish someone backed me up when I tried to call someone out about vaping in my section last season. The usher said they didn‚Äôt see it.\\t-1\\nQT @katebyrnepower: That‚Äôs just chicago, baby ; Currently browsing the Logan square monument for my friend‚Äôs juul that she lost while making out with a stranger that she met at the owl........Easy could never\\t0\\nnobody: my brain: hit ur juul\\t0\\n@NewYorker @jiatolentino Can‚Äôt vape, but you can poop anywhere at your leisure.\\t0\\nanyone else who doesn\\'t care about spending time with their father wanna go to hookah tonight!\\t0\\nforbidden lovers: lip gloss, my vape\\t0\\nsimply due to my CBGa allergy. No one will have fun if I swell up like a puffer fish and have to go to the ER. Vape blends/oils without are perfectly fine provided you share üòò also while there will be alcohol present, I will only allow one drink/flight at the brewery. SSC is key\\t0\\n@LivinginWhy Gotta go what ever creature you are, like me all trump supporters have businesses jobs etc , So it\\'s time to go to bed and get up and work now go vape take some money out of your mom\\'s wallet and go buy a pop good night loser\\t0\\n@HillaryClinton Anyone here into guns? Vaping?\\t0\\nYOOOO I JUS CAUGHT MY BROTHER WIT A JUUL IM FINNA BEAT THE SHIT OUTTA HIS ASS\\t-1\\nI think I just heard my husband ask ‚Äúwhat is your favorite vape‚Äù in the other room so I guess I don‚Äôt know who he is anymore.\\t-1\\n@MarlenaRodrigz I have 3 half empty cartridges and nothing to help me heat them up and suck smoke out of it. I ordered a nice big vape pen so I won‚Äôt keep losing them but I‚Äôm sober and irritable. Arg.\\t0\\ni completely HATE when people try to one up you on a shitty home life or bad situations. I‚Äôve SEEN bad home lives and I‚Äôve witnessed the conscious and subconscious trauma and pain a child goes through and trust me your mom taking away your juul isn‚Äôt the same\\t-1\\nQT @MeGustaJoshua: I feel attacked. ; My stomach is killing me this morning Its almost as if Iced Coffee and Juul is not a meal replacement\\t0\\n@_Simbasworld I can\\'t believe in this day and age people are still smoking cancer sticks when they could be smoking or vaping trees ü§∑\\u200d‚ôÄÔ∏è\\t1\\nMy juul friends.. where‚Äôs the cheapest place to buy a juul. I lost mine and I‚Äôm not trying to be dumb and spend $75 on one again from a vape shop.\\t1\\n@IamBroony Don‚Äôt vape live longer\\t-1\\nQT @MsMeowkinz: Lmfaaaoooooooo yoooo I remember the daysü•¥ü•¥ü•¥ ; smoked mad hookah this weekend, I sound like Tracy Morgan today ü•¥\\t0\\n‚ÄúI go to the bathroom every 2 hours so I can hit my juul‚Äù\\t0\\ni made fun of people who vape for so long until they made a usb stick that curbs my desire to eat toothpaste\\t-1\\n@ItsAllAboutDe #VapeLyfe\\t0\\n@lachlan hate/rape/vape is Akin\\'s version of \"wake/bake/skate,\" perhaps\\t0\\nHey Wind Vapes thanks for the follow!\\t0\\nremember kids next month is no juul july. can you go the whole month without hitting your juul üò≥\\t-1\\n@neamhrialta If you own a juul this birthday should probably be your last\\t-1\\nTime to vibe to some music and have a good vape session üëåüèæüòå\\t0\\nLol I think about vaping again all the time but I know I‚Äôm not financially stable enough to be addicted to nicotine.ü§¶üèæ\\u200d‚ôÇÔ∏èüò≠\\t0\\nQT @ayyebabygirl_: On God fr fr ; A paint and sip class, poetry slams, picnics in the park, cooking classes, wine tasting, hookah lounges, hiking, camping, road trips... ALL DATE IDEAS ID LOVE TO EXPERIENCE ‚ù§Ô∏è\\t1\\nSo my vape keeps saying \"check batteries\" everytime I try to hit it Like I haven\\'t had a cigarette in over 2 months don\\'t do this to me now :/\\t0\\n‚ÄúKeeley you got $30 I can borrow?‚Äù ‚ÄúNo, why?‚Äù ‚Äúoh someone‚Äôs selling their JUUL & I thought about buying it‚Äù-@KendalQuillen\\t0\\nQT @ZoeyHertz: v happy that i lost my juul for 6 months and it doesn‚Äôt work now ; I have been juuling for 2 years and now I have pre oral cancer. So stop juuling kids lol\\t-1\\n@ISDM27 Me after a cbd vape hit\\t0\\nme and aspen have matching vapes..\\t0\\n@MenlionD U so fucking dirty for that lmao. Vaping is nasty and the loads of nicotine in it. You should try a wax pen next time . The stuff is weed rolled up in a pen.\\t-1\\nThe city of San Francisco has become the first city to BAN e-cigarettes. And the market leader, ‚ÄúJuul‚Äù is based in San Francisco...I like where this is going üòä\\t0\\nQT @ItsSnowBeatz: üòÇüò≠ ; This nigga Karlous said girls who smoke hookah pussy taste like volcano dust..DAWGüòÇüòÇ\\t0\\nQT @ScottGottliebMD: What did you do as FDA Commissioner to encourage this option? You could\\'ve called Mitch Zeller during any day of your tenure and told him to get working on this option. ; Vapes should seek to separate from products like JUUL to establish potential to help adults. Also, e-cig makers who don‚Äôt suffer JUULs youth affliction should consider OTC pathway as option to secure market approval. There are options for small vape stores that target only adults\\t1\\n@PatriotMichaelO Hey Michael, Yes we‚Äôre so sorry for the delay we should have these kinks worked out very soon. Thanks so so much for your support. What MG do you vape?\\t0\\n@randall__hill I have a vape so it makes it even worseü§£\\t0\\nWhat is the point of hookah fr ?\\t0\\n@DENlM_DADDY get a fucking vape loser\\t-1\\nAlex literally lost his juul last night... we went to Qt rn and they had it. üíØ\\t0\\ni wish i had friends, to smoke hookah withüò¢üôÑ.\\t0\\nMy bed is calling me... this rain not it lol I wanted hookah or a drink but fuck it\\t0\\n@TREESVlNYL *blows vape smoke trying to be cool* *brother ruins it by blowing it away* ‚ÄúADAM‚Äù\\t0\\nsome juul pods be like snap crackle pop\\t0\\nQT @FreshOj24: LMFAOOOOOOOOOO Im glad you know ; Dominican niggas from DR don‚Äôt know how to pass the hookah.\\t0\\n@aptly_engineerd first there was juul now there is pussay, the only vape stick made with authentic vaginal mucus it will get you On\\t1\\nIf you had a dollar for everytime you open a snap theres a fat bitch twerking or hella hookah smoke how much money would you have\\t0\\n@baha100 They can lie. So they do. Meanwhile, vape companies are not allowed to tell the truth - that vaping is vastly safer than smoking...\\t1\\nRandom cute girl approached me but saw me vaping so she asked someone else for a lighter. This isn‚Äôt the first time this happened to me... I shall carry a lighter at all times ü§î\\t0\\nLmfaoooooo 20$ dollar Hookah ????? How much for a re-fill? 5 DOLLARSSS ?? Lmfaooo üòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇüòÇ\\t0\\n@BleacherReport @Sportsnet Someone should teach No 2 how to smoke a cigar @RealSkipBayless @Zico31700472 @RPZADO @YvesGWM @fanintoronto guess they didn‚Äôt expect the win so they didn‚Äôt practice this part - he is smoking a cigar like he is smoking a Hookah @nabilabouhabib\\t0\\nI love my vape pen. Baked like a potato. Totally a stoner yo! üå¨üåøüçÉ\\t0\\nQT @demithacreator: Shisha ; What do smoke? Weed, SK, Arizona or Loud?\\t0\\ni once saw 8-9 girls join in union over one juul pod no cap\\t0\\nAnybody ever use coconut water in they hookah ?\\t0\\nI might be stupid but I‚Äôm not stupid enough to own a juul\\t-1\\nMe smoking a juul and drinking tequila in the bathroom of the jitney-the young Bitch ride clean don‚Äôt it!\\t0\\nQT @JoshDuckBurton: I think Yang should rock a Hawaiian shirt and rip a Juul during the next segment #DemDebate #YangGang2020 ; I‚Äôm surprised Yang hasn‚Äôt leaned backed and ripped a fat Juul while not wearing a tie and says ‚Äúyeah, bro.‚Äù #DemDebate2 #DemocraticDebate\\t0\\nQT @amoeffner19: i took it home today ü•¥ ; there‚Äôs a juul sitting in the office at work and i‚Äôm the only manager that smokes them so it must be mine right??? should i grab it???\\t0\\n@JaiTheGuy3 My school smells like vape and marijuana all the time LOL\\t0\\nQT @ARPdidTHAT: @RachelKathryn__ üôÑüôÑ clocked ; White Claw is just Juul water.\\t0\\n@brandonco4 Juul idc but people who smoke cigarettes in traffic are assholes. Forcing me to put my AC on the button that makes it recycle the inside air? Die screaming motherfucker.\\t0\\nif you smoke virginia tobacco flavored juul pods i‚Äôm just gonna go ahead and assume you smoke crack also\\t-1\\nFemale bathroom attendants generally don‚Äôt seem to yell at you for vaping so based on that I believe we need more women in office\\t0\\ni still can‚Äôt believe they took my full pack of cigs, lighter, AND my goddamn juul going through security...i‚Äôm honestly more mad about that than anything else wtf\\t0\\ngood hookah lounges in atlanta?\\t0\\nQT @sardashhhhhhhhh: I don\\'t juul but love the optimism ; if the juul doth crackle...big problems we tackle\\t-1\\n@DrBobBullard Ugh! Juul does more then just rhyme with KOOL. (SMH)\\t0\\n@zookepermusic @DillonFrancis Now u can‚Äôt be vaping enoughüò§\\t0\\nSo tonight at work a coworker stole my vape mod. That thing was over $100... I‚Äôm so disappointed in humans.\\t0\\nhookah and drinks errday\\t0\\nCarts/vapes are trash. I‚Äôd rather just roll up\\t-1\\nHampton beach and Hookah, i‚Äôm w itüòõ\\t0\\nI have saved a shit ton of money already switching to a Juul and also I don‚Äôt reek of cigarettes. I‚Äôve had 2 cigarettes in the past 4 days and the week before it took me an entire week to smoke one pack. daddy is living.\\t1\\nQT @ARPdidTHAT: I feel attacked ; White Claw is just Juul water.\\t0\\n‚ÄúIs your teenager irrational and moody, like every teenager in the entire history of the human species? It must be that newfangled vaping!‚Äù\\t0\\nStarting July 1, all Walmart and Sam\\'s Club locations will increase the minimum age for tobacco purchases to 21. The retailers will also stop selling the fruit-flavored vaping systems popular with teenagers. Will other companies follow suit? Read more via @USAToday.\\t0\\nPeople are fucking fiends now days, i could put a hit on someone for a Juul pod\\t0\\nQT @NessaTabasco: ü§¢ü§¢ ; Son how did i lose my juul last night\\t0\\n@meetdosist @ShopMedMen I tried the Calm first as I have some lung damage from lupus and wasn\\'t sure I\\'d be able to vape successfully. Now that I know I can, I plan to go back for the relief one for bedtime use. The MedMen rep was really helpful. PS: my cat LOVES the smell. LOL\\t1\\nQT @massisays_: Same but I‚Äôm also the hookah hogger ; I hate hookah hoggers\\t0\\nQT @johngraycpa: Dumbest tweet of the day? ; Wait a minute. Muslims in NE who own ‚ÄúHookah‚Äù bars are NOT required to sell alcohol because alcohol is against their religious beliefs but Christian bakers in NE must bake cakes for LGBTQ even though it‚Äôs against THEIR religious beliefs? No dbl standard or discrimination there?\\t0\\n@kyli_schmitt11 Someone literally stopped me yesterday to ask me for a hit of a vape, it was kinda sad tbh. I don‚Äôt drink coffee or soda so when I have caffeine I‚Äôm wired\\t0\\nWoke up, looking for my vape pen. Found a cigarette instead with a hole in it. I fixed it with a piece of a Zig Zag paper. Just to let you all know how resourceful/borderline I really am.\\t0\\n‚ÄúAre you vaping in the house?‚Äù ‚ÄúNo it‚Äôs just fabreeze!!‚Äù\\t0\\n‚ÄòGuy who smokes his juul and asks you if you‚Äôve ever had white claw‚Äô is the new ‚Äògirl with a teal Hydroflask telling you she still has ice in there since the day before‚Äô\\t0\\n@PrettyNu1021 See u would know more about hookah than me didn‚Äôt know that‚Äôs making ppl gain weight lol\\t0\\nDropped my juul in the toilet... bought a new one. Two days later did the same thing... fml\\t0\\ni laugh hard af when vape is life lol\\t0\\n@347Gabe im throwing ur juul out\\t0\\nI want a margarita and some hookah\\t0\\nQT @LeedyLauren: Everyone should know this by now ; PSA My friend was roofied last night at the Hookah Lounge in College Station. Thank god I was there to save her but PLEASE ladies don‚Äôt take drinks from anyone!!! And keep an eye on your drink!!\\t0\\nme: just a pack of mint juul pods pls cashier: wow..show off me: cashier: me: cashier: ...$16.95\\t0\\nCrocs on my feet packin‚Äô that heat juul between my teeth thank you\\t0\\n@ShaalanBeg @PatelOncology @JackWestMD I think that ship has sailed and it‚Äôs too late to make vaping a regulated and safe smoking cessation tool, too worked into the culture of teens (as the makers planned). I think banning is the only way to head this off now.\\t-1\\nwhy any of y\\'all vape when it\\'s probably killing you is beyond me. I\\'ll only fill my lungs with what god intended me to: latex paint and oxygen üëãüëãüëã\\t-1\\n@afrozekbeshir really @‚Äòing everyone with a juul broüòÇ\\t0\\nthat juul buzz be hittin my feet more than anything no cap\\t0\\nrick ross voice sound like he been smoking hookah since birth.\\t0\\nIf my grandma buys me juul pods to join the air force should i do it?\\t0\\nPlatinum vapes really out here w a whole ass billboard ü•¥\\t0\\n@curlymamaw @CDCTobaccoFree Only chemical in vaping is the nicotine. And you can get it without it.\\t1\\nfor someone who only hits the occasional social vape, I listen to steamroller TOO much\\t0\\nQT @cheydandelion: refillable pods / bigger pods would be cool too ; the juul company should start making their juuls to just have a usb charger on the bottom of the device itself. So u could just plug your juul straight into any USB port like in the car and never have to worry about losing that tiny little charging thing anymore.\\t0\\n@ARBryant4 Vape smells are gross\\t-1\\nA 13 year old girl smoking a juul just asked me where the after party is It‚Äôs 1PM clout kids are built DIFFERENT\\t-1\\nIG live is weird as hell to me. Imagine being at the club with your friends and instead of enjoying your time w your friends, u decide to broadcast tyourself sitting down smoking hookah saying ‚Äúhi wassup‚Äù every minute to random people who pop up.\\t0\\nQT @rustygunter: That\\'s great!üòÅüòÅüòÇü§£ ; Guys that vape, do y‚Äôall shave your pussy completely or leave a landing strip?\\t0\\ngunna setup outside my old high school and sell juul pods to students out of my 2004 VW Jetta like the entrepreneur I am\\t0\\n@warmdamn Wait which is it the vaping or the 2 consecutive dates...\\t0\\nQT @AddieMarieP: Me tries to hangout with someone... Skinny girl with a nice smile: I‚Äôve got my juul Me: ; Fucking cunt\\t0\\nBroke my vape pen at work ... but it‚Äôs still hitting üò≠üò≠üò≠üò≠üò≠\\t0\\nI hit the juul and i cant feel my feet rn üòÇ\\t0\\nThat hookah shit lame afff\\t-1\\nthere‚Äôs nothing better than taking a crisp hit of my vape early in the morning ü§£\\t0\\n@aspirecigs #HappyFathersDay @oddworld911 ,@philbh77 ,@Alien_Semen ,@axelbeam ,@dr_amp815 ,@irwansyah_vape ,@ShadeyVapes\\t0\\nI wanna go to the hookah lounge but I got no friends lmao\\t0\\n@CNN @AngelusMerula There was a young man in NJ who was found slumped over in his car. His vape apparatus exploded and a small sliver of metal went through is carotid artery and he died before he could open the car door.\\t-1\\n@trippingpossum Sorry for the spam lol. I was taking it orally before, under the tongue and it just..wasn\\'t really lasting all that long. Now I have this vape pod thingy, and I can just take a few drags off of it when I start feeling anxious or tense and I feel a wave of calm flush over me pfft\\t1\\nDM me if you can sell me a vape cart in the estates\\t0\\n@SMOKTECHLOGY I‚Äôve never had a vape because I‚Äôve never thought to switch\\t-1\\n@B_Real Flowers for home. Vapes if traveling.\\t0\\n@geekyJustinLee Top 5 is pretty generous. Though I\\'m definitely above the dude whose emails I keep getting. He orders SO MUCH VAPE JUICE. When he\\'s not in court-ordered drug therapy.\\t0\\n@Marruccaaa On g after I used the vape my lungs big asf üòÇ I was smoking that hoe for 5 min before I did that\\t0\\n@wendyvapes @enbflavor @ijoyglobal @Mike_Vapes @Winnie_hellvape That sounds amazing my friend Wendy...I actually am for once in the last 6 months going to be able to vape on my top ever favorite liquid put on this planet....MBYC Fried by SicBoy...I will be bringing it with me as I get admitted into the hospital today...I\\'m scared.. :-(\\t1\\nI‚Äôm in Paris in the bathroom and my flight is boarding so I ran to the bathroom. I‚Äôm now on the toilet chugging the rest of my champagne and getting my vape hits in. I‚Äôm ashamed of myself\\t0\\nThe California Democratic Convention is sponsored by Uber, Visa, Juul, Fox, and AirBnB. WTAF? #CADem2019\\t-1\\nJust like in the movies, sitting up with a pillow against the headboard after incredible sex, smoking a Juul\\t1\\n@xowenm tell me why i thought he had a juul in his hand\\t0\\n@lethargicwaldo @cincynancy If you put your ear up to the can and are really silent, you can hear the Juul hit Kreygasm\\t0\\nIn fairness I was prob the 2010 equivalent of that kid that vapes in class\\t0\\n@tbformayor I fw hookah now ü§£ at first thought it was useless\\t0\\nthis is ‚Äúno juul july‚Äù bitch\\t-1\\n@aaron_WALDRUP I hate it I hate all of it Also bring me a juul charger to work.....mine died n i‚Äôm sad\\t0\\nThey putting round up in dank vapes üòÇ\\t0\\nGushers vape got me fried\\t0\\nSan Francisco has become the first US city to ban e-cigarette sales until their health effects are clearer. #Sirius XM 115\\t-1\\n@kkillah_x nobody goes outside so even if you did try to go to a bar or a hookah lounge they‚Äôre EMPTY so it‚Äôs still not fun üòÇüòÇüòÇüòÇ\\t0\\n@stelIhudg you have a juul addiction & i am glad i don‚Äôt have a juul addiction üòÄ\\t-1\\n@AmericanRose8 @Montchelle66 @charzdesigns @KassMiass @TexasChick1968 @khenry657 @ms_kux @PhoebeDRobinson @LJT_is_me @ElizabethQE20 @Elaines2cents @almostjingo @michael_szumega @surfagogo @multitasker333 @mizdonna @jskielb3 @JenniferKashani @DrLaura2th @CyndeVita @Natashasjam In Colorado you can buy the CBD oil, under tongue. No high, just the pain relief. You can buy at vape stores, don‚Äôt even have to go to MMJ store. My neighbor has cancer and he says it helps!\\t1\\nWent to get coffee with my dad this morning. I talked him into buying a juul\\t0\\nno cops at pride just a guy named Travis in a deadpool snapback and his torrential vape clouds\\t0\\nSmoking a juul is not better than smoking cigarettes if you‚Äôre pregnant you shouldn‚Äôt be smoking. Not sorry. Your child being healthy should mean more than feeding a habit ü§∑üèº\\u200d‚ôÄÔ∏è.\\t-1\\nboy dem vapes sumn serious i almost died\\t-1\\nTheoretically, you can put lean in a Juul.\\t0\\n@StoneHamlin If I ever compliment vaping, call the police because I‚Äôve been kidnapped\\t-1\\nQT @addvsen: This is exactly why I stopped going and why the city of Austin decided to cut BOTG short with less concerts during summer. The new wave of ppl going/moving here are trash af people. ; last night after blues on the green, zilker was fucking TRASHED. i‚Äôm talking juul pods, beer, to go boxes, bags...a lot of it within 100 feet of a trash can. a lot of you guys pretend to care about the earth for twitter points. only about 5 of us stayed to clean. fuck y‚Äôall\\t-1\\nHeelys on, juul charged, hat backwards. Watch out world.\\t0\\n@jordan_gravelin @jbarro The percentage of teenagers vaping is growing by 50% a year...25% in 2017, 38% in 2018, and signs pointing towards 50-60% this year. Draconian measures worth considering to reverse this quickly.\\t-1\\n69 dollars for a hookah by the beach?! Shit better come with some oysters and henny.\\t0\\n@PPonsetto @FitzTheReporter @GreatDismal @truthorange Can\\'t fault them for trying, vaping is an epidemic with teens\\t-1\\nafter this last coil burns i‚Äôm officially giving up vaping\\t-1\\nYou, a peasant: Vape Mod My girlfriend‚Äôs mother, a god: Wireless Hookah üòàüòà\\t0\\nthis @buyIegaImeds vape i got is the shit i\\'m never buying any other CBD vape ever again\\t-1\\nQT @AmericanLungPA: Agreed! ; @RepRabb The U.S. Surgeon General recently declared youth e-cigarette use an epidemic. Now more than 1 in 4 high school students use e-cigarettes regularly. Now is not the time to defund Pennsylvania‚Äôs tobacco prevention programs when they are needed most #SaveMSAinPA\\t-1\\nSeriously though, for a city with a retail vacancy crisis, and where small businesses are already struggling to survive, this is a death knell for a whole category of businesses‚Äîvape stores‚Äîand a huge hit to the city\\'s beloved corner stores\\t0\\n@BuddyGoodlet I‚Äôm thinking you mean Juul and I don‚Äôt do that crap buddy.\\t-1\\nBefore hand I gave her a sweet smile but I got a b- itch face & google eyes in return. I kept smiling & brushed it off. Afterwards she comes army marching after me as I was vaping outside. Human behavior # 101 ‚Äúarmy march‚Äù walking is a form of aggression.\\t0\\nNeed a hookah at home üò©\\t1\\nLeft my damn juul in the rain and this must be what a real heartbreak feels like üò£\\t0\\nit has been 24 hours since my lungs have had precious juul vapor in them. keep me in your thots & prayers\\t0\\n@lovemyman_ San Francisco outlaws vaping and plastic straws however permits heroin use, public defecation , and public sex displays. Taxes up 40% and highest gas tax in NATION. Wow..someone still lives there?\\t0\\nQT @MC_Cash75: .@KillEFFY but with a juul ; Just saw a wrestler do the HHH water bottle gimmick but with a vape pen.\\t0\\nQT @scottbudman: WTF San Francisco? You fascist demagogues just might wanna do bans on feces, urine, hypodermic needles & typhus in the streets. ; The first major city in the country to ban the sale of electronic cigarettes, San Francisco, is the home of Juul. SF also recently approved a ban on the sale of flavored tobacco and a tax on sugar-sweetened drinks.\\t0\\nWow only harlem would have hookah in a hair salon\\t0\\nTo be honest, I\\'m still #AgainstSmoking cigarettes and yet, I just started #vaping. Does this make me a hypocrite? üí®\\t1\\nQT @tobaccodad: Mood ; Thinking about a vape cloud so massive that it blocks the sun for an hour\\t0\\nQT @BIGSANT: üòÇüòÇüòÇ ; Your MCM smokes hookah.\\t0\\nSomeone just asked if anyone has a juul charger in our company-wide Slack.. millennials have officially taken over the workforce\\t0\\nQT @Alexlovesbooty1: bitch fuck you i texted you back üòÇ ; Since you don\\'t wanna text me back bitch I left my juul pods in your car @xobabykaylee\\t0\\nQT @arimcneary: people are really out here addicted to a flash drive ; I knew I was more superior to my peers when they became juul addicts and I didn‚Äôt\\t-1\\nQT @adam22: All of the above ü§∑üèæ\\u200d‚ôÇÔ∏è ; 2015 = molly 2016 = lean 2017 = xans 2018 = mango juul pods\\t0\\nwhat the hell kind of vapes in 2019\\t-1\\nMy grandparents geeneration used to smoke a cigarette after sex. Now we just hit the juul. üòÇ #juul #facts\\t1\\n@MatthewWSmith2 What about juul pods and tide pods though\\t0\\nI feel like my juul is more addicting than cigarettes ever were. But idgaf cuz it‚Äôs under half the cost of smoking and doesn‚Äôt kill me!!!\\t1'\n",
        "\n",
        "file = open(\"input_data.txt\",\"w\") \n",
        " \n",
        "file.write(content)\n",
        " \n",
        "file.close() "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "sAI3v5qWDU1q",
        "outputId": "e5d0d2e6-750c-4e91-891c-67ab9ad3762d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        }
      },
      "source": [
        "pip install tensorflow"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.15.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.8)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.27.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.17.5)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.34.2)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.1.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.2.2)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.1)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.9.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.1)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.10.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow) (45.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "fse6LBkQDU1t",
        "outputId": "094ba687-8e91-4974-e53f-119a94f5771a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "pip install tensorflow_hub"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow_hub in /usr/local/lib/python3.6/dist-packages (0.7.0)\n",
            "Requirement already satisfied: numpy>=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.17.5)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (1.12.0)\n",
            "Requirement already satisfied: protobuf>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow_hub) (3.10.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.4.0->tensorflow_hub) (45.2.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "mSz-7DUQDU1x",
        "outputId": "137d9206-0d8a-4a86-9e0f-3072427ca5ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        }
      },
      "source": [
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "from datetime import datetime\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "\n",
        "print(\"tensorflow version : \", tf.__version__)\n",
        "print(\"tensorflow_hub version : \", hub.__version__)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensorflow version :  1.15.0\n",
            "tensorflow_hub version :  0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tV6PHF1jDU10",
        "outputId": "56704e20-cd60-49e6-a606-660df2ed9f98",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "#Importing BERT modules\n",
        "import bert\n",
        "from bert import run_classifier\n",
        "from bert import optimization\n",
        "from bert import tokenization\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:87: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "FpBGRKhoDU15",
        "outputId": "b2702191-386d-4a72-8094-04a06e1a8a01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Set the output directory for saving model file\n",
        "OUTPUT_DIR = 'model'\n",
        "\n",
        "#@markdown Whether or not to clear/delete the directory and create a new one\n",
        "DO_DELETE = False #@param {type:\"boolean\"}\n",
        "\n",
        "if DO_DELETE:\n",
        "  try:\n",
        "    tf.gfile.DeleteRecursively(OUTPUT_DIR)\n",
        "  except:\n",
        "    pass\n",
        "\n",
        "tf.gfile.MakeDirs(OUTPUT_DIR)\n",
        "print('***** Model output directory: {} *****'.format(OUTPUT_DIR))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Model output directory: model *****\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "KW__OiQrDU19",
        "colab": {}
      },
      "source": [
        "train = pd.read_table(\"input_data.txt\")\n",
        "train['Opinion'].value_counts()\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "train, test =  train_test_split(train, test_size = 0.2)\n",
        "train, val =  train_test_split(train, test_size = 0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "cL1RqYQvDU2A",
        "outputId": "c618f1ce-b38a-48ba-99a5-b3f7b4ae5b3d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "#Training set sample\n",
        "train.head(5)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Contents</th>\n",
              "      <th>Opinion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>@Simonee_99 ian never smokin on hookah again</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>I want to go to the hookah bar</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>QT @oxymme: Omggg I felt this ; ima still smok...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>QT @donnicholass: üó£üó£üó£üó£üó£ ; ‚Ä¢ DAY PARTY AT ZONA ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>Dropped my juul in the toilet... bought a new ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Contents  Opinion\n",
              "38        @Simonee_99 ian never smokin on hookah again       -1\n",
              "46                      I want to go to the hookah bar        0\n",
              "117  QT @oxymme: Omggg I felt this ; ima still smok...        0\n",
              "93   QT @donnicholass: üó£üó£üó£üó£üó£ ; ‚Ä¢ DAY PARTY AT ZONA ...        0\n",
              "311  Dropped my juul in the toilet... bought a new ...        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oeRvt5_sDU2C",
        "outputId": "6e7762a8-ad3f-4777-ba4a-0d0b0adaf3dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "test.head(5)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Contents</th>\n",
              "      <th>Opinion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>@lilfryh Didn‚Äôt say mango juul pods</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>Smoking a juul is not better than smoking ciga...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>talkin bout ‚ÄòiLl nEvEr sMoKe a CiG‚Äô but use a ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>remember kids next month is no juul july. can ...</td>\n",
              "      <td>-1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>Can somebody send a juul to Mexico please</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Contents  Opinion\n",
              "72                 @lilfryh Didn‚Äôt say mango juul pods        0\n",
              "366  Smoking a juul is not better than smoking ciga...       -1\n",
              "123  talkin bout ‚ÄòiLl nEvEr sMoKe a CiG‚Äô but use a ...       -1\n",
              "245  remember kids next month is no juul july. can ...       -1\n",
              "19           Can somebody send a juul to Mexico please        0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "qnuyUwiwDU2F",
        "outputId": "6bf15732-b505-49e0-c1f8-de72ff0681af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(\"Training Set Shape :\", train.shape)\n",
        "print(\"Validation Set Shape :\", val.shape)\n",
        "print(\"Test Set Shape :\", test.shape)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Set Shape : (256, 2)\n",
            "Validation Set Shape : (64, 2)\n",
            "Test Set Shape : (80, 2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "QSEzWWOmD4ON",
        "outputId": "4aa82137-3a71-4e2d-d907-e5717f8492b8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "train['Opinion'].value_counts()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    179\n",
              "-1     40\n",
              " 1     37\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ix0XxkswD8PU",
        "outputId": "06854724-01df-4917-fde2-891863f68808",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "val['Opinion'].value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              " 0    46\n",
              "-1    11\n",
              " 1     7\n",
              "Name: Opinion, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "OgQSUS4mDU2I",
        "outputId": "7839946b-06b2-42bc-f45b-ff66262b07ba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "train.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Contents', 'Opinion'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Uik3p90zDU2K",
        "outputId": "346b1d25-80fd-46ad-f767-b9008862cdde",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "#Distribution of classes\n",
        "import matplotlib\n",
        "train['Opinion'].value_counts().plot(kind = 'bar')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f04bde63a58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD4CAYAAAAXUaZHAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ylk7LSD3DU2N",
        "colab": {}
      },
      "source": [
        "DATA_COLUMN = 'Contents'\n",
        "LABEL_COLUMN = 'Opinion'\n",
        "# The list containing all the classes (train['SECTION'].unique())\n",
        "label_list = [-1,0,1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "7Om2YmuTDU2Q",
        "colab": {}
      },
      "source": [
        "train_InputExamples = train.apply(lambda x: bert.run_classifier.InputExample(guid=None,\n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)\n",
        "\n",
        "val_InputExamples = val.apply(lambda x: bert.run_classifier.InputExample(guid=None, \n",
        "                                                                   text_a = x[DATA_COLUMN], \n",
        "                                                                   text_b = None, \n",
        "                                                                   label = x[LABEL_COLUMN]), axis = 1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "wUZz71TBDU2T",
        "outputId": "c9c88c27-405a-4011-caef-1721ba79f6fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "train_InputExamples"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "38     <bert.run_classifier.InputExample object at 0x...\n",
              "46     <bert.run_classifier.InputExample object at 0x...\n",
              "117    <bert.run_classifier.InputExample object at 0x...\n",
              "93     <bert.run_classifier.InputExample object at 0x...\n",
              "311    <bert.run_classifier.InputExample object at 0x...\n",
              "                             ...                        \n",
              "176    <bert.run_classifier.InputExample object at 0x...\n",
              "92     <bert.run_classifier.InputExample object at 0x...\n",
              "10     <bert.run_classifier.InputExample object at 0x...\n",
              "301    <bert.run_classifier.InputExample object at 0x...\n",
              "219    <bert.run_classifier.InputExample object at 0x...\n",
              "Length: 256, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bNCvtJVvDU2W",
        "outputId": "809a9791-0c84-4c3e-e833-15c3674f8495",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 187
        }
      },
      "source": [
        "print(\"Row 0 - guid of training set : \", train_InputExamples.iloc[0].guid)\n",
        "print(\"\\n__________\\nRow 0 - text_a of training set : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"\\n__________\\nRow 0 - text_b of training set : \", train_InputExamples.iloc[0].text_b)\n",
        "print(\"\\n__________\\nRow 0 - label of training set : \", train_InputExamples.iloc[0].label)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Row 0 - guid of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - text_a of training set :  @Simonee_99 ian never smokin on hookah again\n",
            "\n",
            "__________\n",
            "Row 0 - text_b of training set :  None\n",
            "\n",
            "__________\n",
            "Row 0 - label of training set :  -1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "dc3ZAW5aDU2Z",
        "outputId": "14fc2636-aeda-4005-e03c-29e0e7766114",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "# This is a path to an uncased (all lowercase) version of BERT\n",
        "BERT_MODEL_HUB = \"https://tfhub.dev/google/bert_uncased_L-12_H-768_A-12/1\"\n",
        "\n",
        "def create_tokenizer_from_hub_module():\n",
        "  \"\"\"Get the vocab file and casing info from the Hub module.\"\"\"\n",
        "  with tf.Graph().as_default():\n",
        "    bert_module = hub.Module(BERT_MODEL_HUB)\n",
        "    tokenization_info = bert_module(signature=\"tokenization_info\", as_dict=True)\n",
        "    with tf.Session() as sess:\n",
        "      vocab_file, do_lower_case = sess.run([tokenization_info[\"vocab_file\"],\n",
        "                                            tokenization_info[\"do_lower_case\"]])\n",
        "      \n",
        "  return bert.tokenization.FullTokenizer(\n",
        "      vocab_file=vocab_file, do_lower_case=do_lower_case)\n",
        "\n",
        "tokenizer = create_tokenizer_from_hub_module()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/tokenization.py:125: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n",
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "0cVfZCY_DU2b",
        "outputId": "6151d843-dcc0-406a-b1c5-be0bd50bdca0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Here is what the tokenised sample of the first training set observation looks like\n",
        "print(tokenizer.tokenize(train_InputExamples.iloc[0].text_a))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['@', 'simone', '##e', '_', '99', 'ian', 'never', 'sm', '##oki', '##n', 'on', 'hook', '##ah', 'again']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "SugRR62BDU2e",
        "outputId": "a63ee5bf-67f6-4945-df42-46a54396d9fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# We'll set sequences to be at most 128 tokens long.\n",
        "MAX_SEQ_LENGTH = 144\n",
        "\n",
        "# Convert our train and validation features to InputFeatures that BERT understands.\n",
        "train_features = bert.run_classifier.convert_examples_to_features(train_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "val_features = bert.run_classifier.convert_examples_to_features(val_InputExamples, label_list, MAX_SEQ_LENGTH, tokenizer)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/run_classifier.py:774: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 256\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 256\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ simone ##e _ 99 ian never sm ##oki ##n on hook ##ah again [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ simone ##e _ 99 ian never sm ##oki ##n on hook ##ah again [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 14072 2063 1035 5585 4775 2196 15488 23212 2078 2006 8103 4430 2153 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 14072 2063 1035 5585 4775 2196 15488 23212 2078 2006 8103 4430 2153 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: -1 (id = 0)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i want to go to the hook ##ah bar [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i want to go to the hook ##ah bar [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2215 2000 2175 2000 1996 8103 4430 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2215 2000 2175 2000 1996 8103 4430 3347 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ ox ##ym ##me : om ##gg ##g i felt this ; im ##a still smoke the hook ##ah if it ‚Äô s not mint , i ‚Äô m just gonna say ‚Äú you should ‚Äô ve got mint ‚Äù the whole time [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ ox ##ym ##me : om ##gg ##g i felt this ; im ##a still smoke the hook ##ah if it ‚Äô s not mint , i ‚Äô m just gonna say ‚Äú you should ‚Äô ve got mint ‚Äù the whole time [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 23060 24335 4168 1024 18168 13871 2290 1045 2371 2023 1025 10047 2050 2145 5610 1996 8103 4430 2065 2009 1521 1055 2025 12927 1010 1045 1521 1049 2074 6069 2360 1523 2017 2323 1521 2310 2288 12927 1524 1996 2878 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 23060 24335 4168 1024 18168 13871 2290 1045 2371 2023 1025 10047 2050 2145 5610 1996 8103 4430 2065 2009 1521 1055 2025 12927 1010 1045 1521 1049 2074 6069 2360 1523 2017 2323 1521 2310 2288 12927 1524 1996 2878 2051 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ don ##nic ##hol ##ass : [UNK] ; ‚Ä¢ day party at z ##ona ‚Ä¢ no cover | $ 100 reg bottles | $ 15 hook ##ah | $ 5 ref ##ill ##s | outside patio | kitchen available all day ! fm ##i contact me ! sounds by @ dj ##dy ##man ##d x @ dee ##ej ##ay ##be ##bo [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ don ##nic ##hol ##ass : [UNK] ; ‚Ä¢ day party at z ##ona ‚Ä¢ no cover | $ 100 reg bottles | $ 15 hook ##ah | $ 5 ref ##ill ##s | outside patio | kitchen available all day ! fm ##i contact me ! sounds by @ dj ##dy ##man ##d x @ dee ##ej ##ay ##be ##bo [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 2123 8713 14854 12054 1024 100 1025 1528 2154 2283 2012 1062 7856 1528 2053 3104 1064 1002 2531 19723 11015 1064 1002 2321 8103 4430 1064 1002 1019 25416 8591 2015 1064 2648 19404 1064 3829 2800 2035 2154 999 4718 2072 3967 2033 999 4165 2011 1030 6520 5149 2386 2094 1060 1030 9266 20518 4710 4783 5092 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 2123 8713 14854 12054 1024 100 1025 1528 2154 2283 2012 1062 7856 1528 2053 3104 1064 1002 2531 19723 11015 1064 1002 2321 8103 4430 1064 1002 1019 25416 8591 2015 1064 2648 19404 1064 3829 2800 2035 2154 999 4718 2072 3967 2033 999 4165 2011 1030 6520 5149 2386 2094 1060 1030 9266 20518 4710 4783 5092 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dropped my ju ##ul in the toilet . . . bought a new one . two days later did the same thing . . . fm ##l [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] dropped my ju ##ul in the toilet . . . bought a new one . two days later did the same thing . . . fm ##l [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3333 2026 18414 5313 1999 1996 11848 1012 1012 1012 4149 1037 2047 2028 1012 2048 2420 2101 2106 1996 2168 2518 1012 1012 1012 4718 2140 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3333 2026 18414 5313 1999 1996 11848 1012 1012 1012 4149 1037 2047 2028 1012 2048 2420 2101 2106 1996 2168 2518 1012 1012 1012 4718 2140 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 64\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ baha ##100 they can lie . so they do . meanwhile , va ##pe companies are not allowed to tell the truth - that va ##ping is vastly safer than smoking . . . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ baha ##100 they can lie . so they do . meanwhile , va ##pe companies are not allowed to tell the truth - that va ##ping is vastly safer than smoking . . . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 13253 18613 2027 2064 4682 1012 2061 2027 2079 1012 5564 1010 12436 5051 3316 2024 2025 3039 2000 2425 1996 3606 1011 2008 12436 4691 2003 24821 13726 2084 9422 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 13253 18613 2027 2064 4682 1012 2061 2027 2079 1012 5564 1010 12436 5051 3316 2024 2025 3039 2000 2425 1996 3606 1011 2008 12436 4691 2003 24821 13726 2084 9422 1012 1012 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 1 (id = 2)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i just got id ‚Äô d for a ju ##ul charge ##r like ? ? make sure i ‚Äô m 18 years old so i can buy a charge ##r pl ##z [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] i just got id ‚Äô d for a ju ##ul charge ##r like ? ? make sure i ‚Äô m 18 years old so i can buy a charge ##r pl ##z [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2074 2288 8909 1521 1040 2005 1037 18414 5313 3715 2099 2066 1029 1029 2191 2469 1045 1521 1049 2324 2086 2214 2061 1045 2064 4965 1037 3715 2099 20228 2480 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1045 2074 2288 8909 1521 1040 2005 1037 18414 5313 3715 2099 2066 1029 1029 2191 2469 1045 1521 1049 2324 2086 2214 2061 1045 2064 4965 1037 3715 2099 20228 2480 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ am ##oe ##ff ##ner ##19 : i took it home today ; there ‚Äô s a ju ##ul sitting in the office at work and i ‚Äô m the only manager that smoke ##s them so it must be mine right ? ? ? should i grab it ? ? ? [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ am ##oe ##ff ##ner ##19 : i took it home today ; there ‚Äô s a ju ##ul sitting in the office at work and i ‚Äô m the only manager that smoke ##s them so it must be mine right ? ? ? should i grab it ? ? ? [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 2572 8913 4246 3678 16147 1024 1045 2165 2009 2188 2651 1025 2045 1521 1055 1037 18414 5313 3564 1999 1996 2436 2012 2147 1998 1045 1521 1049 1996 2069 3208 2008 5610 2015 2068 2061 2009 2442 2022 3067 2157 1029 1029 1029 2323 1045 6723 2009 1029 1029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 2572 8913 4246 3678 16147 1024 1045 2165 2009 2188 2651 1025 2045 1521 1055 1037 18414 5313 3564 1999 1996 2436 2012 2147 1998 1045 1521 1049 1996 2069 3208 2008 5610 2015 2068 2061 2009 2442 2022 3067 2157 1029 1029 1029 2323 1045 6723 2009 1029 1029 1029 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] today i bought ju ##ul pods good big [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] today i bought ju ##ul pods good big [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2651 1045 4149 18414 5313 26723 2204 2502 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2651 1045 4149 18414 5313 26723 2204 2502 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: None\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ mc _ cash ##75 : . @ kill ##ef ##fy but with a ju ##ul ; just saw a wrestler do the h ##hh water bottle gi ##mm ##ick but with a va ##pe pen . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] q ##t @ mc _ cash ##75 : . @ kill ##ef ##fy but with a ju ##ul ; just saw a wrestler do the h ##hh water bottle gi ##mm ##ick but with a va ##pe pen . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 11338 1035 5356 23352 1024 1012 1030 3102 12879 12031 2021 2007 1037 18414 5313 1025 2074 2387 1037 10706 2079 1996 1044 23644 2300 5835 21025 7382 6799 2021 2007 1037 12436 5051 7279 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1053 2102 1030 11338 1035 5356 23352 1024 1012 1030 3102 12879 12031 2021 2007 1037 18414 5313 1025 2074 2387 1037 10706 2079 1996 1044 23644 2300 5835 21025 7382 6799 2021 2007 1037 12436 5051 7279 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tPYlXy19DU2g",
        "outputId": "92e4b183-e485-42ee-aba0-48c1e7d991e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        }
      },
      "source": [
        "#Example on first observation in the training set\n",
        "print(\"Sentence : \", train_InputExamples.iloc[0].text_a)\n",
        "print(\"-\"*30)\n",
        "print(\"Tokens : \", tokenizer.tokenize(train_InputExamples.iloc[0].text_a))\n",
        "print(\"-\"*30)\n",
        "print(\"Input IDs : \", train_features[0].input_ids)\n",
        "print(\"-\"*30)\n",
        "print(\"Input Masks : \", train_features[0].input_mask)\n",
        "print(\"-\"*30)\n",
        "print(\"Segment IDs : \", train_features[0].segment_ids)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentence :  @Simonee_99 ian never smokin on hookah again\n",
            "------------------------------\n",
            "Tokens :  ['@', 'simone', '##e', '_', '99', 'ian', 'never', 'sm', '##oki', '##n', 'on', 'hook', '##ah', 'again']\n",
            "------------------------------\n",
            "Input IDs :  [101, 1030, 14072, 2063, 1035, 5585, 4775, 2196, 15488, 23212, 2078, 2006, 8103, 4430, 2153, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Input Masks :  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "------------------------------\n",
            "Segment IDs :  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_pE4zmS7DU2j",
        "colab": {}
      },
      "source": [
        "def create_model(is_predicting, input_ids, input_mask, segment_ids, labels,\n",
        "                 num_labels):\n",
        "  \n",
        "  bert_module = hub.Module(\n",
        "      BERT_MODEL_HUB,\n",
        "      trainable=True)\n",
        "  bert_inputs = dict(\n",
        "      input_ids=input_ids,\n",
        "      input_mask=input_mask,\n",
        "      segment_ids=segment_ids)\n",
        "  bert_outputs = bert_module(\n",
        "      inputs=bert_inputs,\n",
        "      signature=\"tokens\",\n",
        "      as_dict=True)\n",
        "\n",
        "  # Use \"pooled_output\" for classification tasks on an entire sentence.\n",
        "  # Use \"sequence_outputs\" for token-level output.\n",
        "  output_layer = bert_outputs[\"pooled_output\"]\n",
        "\n",
        "  hidden_size = output_layer.shape[-1].value\n",
        "\n",
        "  # Create our own layer to tune for politeness data.\n",
        "  output_weights = tf.get_variable(\n",
        "      \"output_weights\", [num_labels, hidden_size],\n",
        "      initializer=tf.truncated_normal_initializer(stddev=0.02))\n",
        "\n",
        "  output_bias = tf.get_variable(\n",
        "      \"output_bias\", [num_labels], initializer=tf.zeros_initializer())\n",
        "\n",
        "  with tf.variable_scope(\"loss\"):\n",
        "\n",
        "    # Dropout helps prevent overfitting\n",
        "    output_layer = tf.nn.dropout(output_layer, keep_prob=0.9)\n",
        "\n",
        "    logits = tf.matmul(output_layer, output_weights, transpose_b=True)\n",
        "    logits = tf.nn.bias_add(logits, output_bias)\n",
        "    log_probs = tf.nn.log_softmax(logits, axis=-1)\n",
        "\n",
        "    # Convert labels into one-hot encoding\n",
        "    one_hot_labels = tf.one_hot(labels, depth=num_labels, dtype=tf.float32)\n",
        "\n",
        "    predicted_labels = tf.squeeze(tf.argmax(log_probs, axis=-1, output_type=tf.int32))\n",
        "    # If we're predicting, we want predicted labels and the probabiltiies.\n",
        "    if is_predicting:\n",
        "      return (predicted_labels, log_probs)\n",
        "\n",
        "    # If we're train/eval, compute loss between predicted and actual label\n",
        "    per_example_loss = -tf.reduce_sum(one_hot_labels * log_probs, axis=-1)\n",
        "    loss = tf.reduce_mean(per_example_loss)\n",
        "    return (loss, predicted_labels, log_probs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ctJybID6DU2o",
        "colab": {}
      },
      "source": [
        "#A function that adapts our model to work for training, evaluation, and prediction.\n",
        "\n",
        "# model_fn_builder actually creates our model function\n",
        "# using the passed parameters for num_labels, learning_rate, etc.\n",
        "def model_fn_builder(num_labels, learning_rate, num_train_steps,\n",
        "                     num_warmup_steps):\n",
        "  \"\"\"Returns `model_fn` closure for TPUEstimator.\"\"\"\n",
        "  def model_fn(features, labels, mode, params):  # pylint: disable=unused-argument\n",
        "    \"\"\"The `model_fn` for TPUEstimator.\"\"\"\n",
        "\n",
        "    input_ids = features[\"input_ids\"]\n",
        "    input_mask = features[\"input_mask\"]\n",
        "    segment_ids = features[\"segment_ids\"]\n",
        "    label_ids = features[\"label_ids\"]\n",
        "\n",
        "    is_predicting = (mode == tf.estimator.ModeKeys.PREDICT)\n",
        "    \n",
        "    # TRAIN and EVAL\n",
        "    if not is_predicting:\n",
        "\n",
        "      (loss, predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      train_op = bert.optimization.create_optimizer(\n",
        "          loss, learning_rate, num_train_steps, num_warmup_steps, use_tpu=False)\n",
        "\n",
        "      # Calculate evaluation metrics. \n",
        "      def metric_fn(label_ids, predicted_labels):\n",
        "        accuracy = tf.metrics.accuracy(label_ids, predicted_labels)\n",
        "        true_pos = tf.metrics.true_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        true_neg = tf.metrics.true_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)   \n",
        "        false_pos = tf.metrics.false_positives(\n",
        "            label_ids,\n",
        "            predicted_labels)  \n",
        "        false_neg = tf.metrics.false_negatives(\n",
        "            label_ids,\n",
        "            predicted_labels)\n",
        "        \n",
        "        return {\n",
        "            \"eval_accuracy\": accuracy,\n",
        "            \"true_positives\": true_pos,\n",
        "            \"true_negatives\": true_neg,\n",
        "            \"false_positives\": false_pos,\n",
        "            \"false_negatives\": false_neg\n",
        "            }\n",
        "\n",
        "      eval_metrics = metric_fn(label_ids, predicted_labels)\n",
        "\n",
        "      if mode == tf.estimator.ModeKeys.TRAIN:\n",
        "        return tf.estimator.EstimatorSpec(mode=mode,\n",
        "          loss=loss,\n",
        "          train_op=train_op)\n",
        "      else:\n",
        "          return tf.estimator.EstimatorSpec(mode=mode,\n",
        "            loss=loss,\n",
        "            eval_metric_ops=eval_metrics)\n",
        "    else:\n",
        "      (predicted_labels, log_probs) = create_model(\n",
        "        is_predicting, input_ids, input_mask, segment_ids, label_ids, num_labels)\n",
        "\n",
        "      predictions = {\n",
        "          'probabilities': log_probs,\n",
        "          'labels': predicted_labels\n",
        "      }\n",
        "      return tf.estimator.EstimatorSpec(mode, predictions=predictions)\n",
        "\n",
        "  # Return the actual model function in the closure\n",
        "  return model_fn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "UjlSvJoxDU2q",
        "colab": {}
      },
      "source": [
        "# Compute train and warmup steps from batch size\n",
        "# These hyperparameters are copied from this colab notebook (https://colab.sandbox.google.com/github/tensorflow/tpu/blob/master/tools/colab/bert_finetuning_with_cloud_tpus.ipynb)\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 3.0\n",
        "# Warmup is a period of time where the learning rate is small and gradually increases--usually helps training.\n",
        "WARMUP_PROPORTION = 0.1\n",
        "# Model configs\n",
        "SAVE_CHECKPOINTS_STEPS = 300\n",
        "SAVE_SUMMARY_STEPS = 100\n",
        "\n",
        "# Compute train and warmup steps from batch size\n",
        "num_train_steps = int(len(train_features) / BATCH_SIZE * NUM_TRAIN_EPOCHS)\n",
        "num_warmup_steps = int(num_train_steps * WARMUP_PROPORTION)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)\n",
        "\n",
        "# Specify output directory and number of checkpoint steps to save\n",
        "run_config = tf.estimator.RunConfig(\n",
        "    model_dir=OUTPUT_DIR,\n",
        "    save_summary_steps=SAVE_SUMMARY_STEPS,\n",
        "    save_checkpoints_steps=SAVE_CHECKPOINTS_STEPS)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ATZ3JyoXDU2s",
        "outputId": "b1198f10-0214-4bf3-ca68-d38e940777f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "#Initializing the model and the estimator\n",
        "model_fn = model_fn_builder(\n",
        "  num_labels=len(label_list),\n",
        "  learning_rate=LEARNING_RATE,\n",
        "  num_train_steps=num_train_steps,\n",
        "  num_warmup_steps=num_warmup_steps)\n",
        "\n",
        "estimator = tf.estimator.Estimator(\n",
        "  model_fn=model_fn,\n",
        "  config=run_config,\n",
        "  params={\"batch_size\": BATCH_SIZE})"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04b587f518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Using config: {'_model_dir': 'model', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': 300, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
            "graph_options {\n",
            "  rewrite_options {\n",
            "    meta_optimizer_iterations: ONE\n",
            "  }\n",
            "}\n",
            ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_session_creation_timeout_secs': 7200, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f04b587f518>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F0NbpJ31DU2v",
        "colab": {}
      },
      "source": [
        "# Create an input function for training. drop_remainder = True for using TPUs.\n",
        "train_input_fn = bert.run_classifier.input_fn_builder(\n",
        "    features=train_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=True,\n",
        "    drop_remainder=False)\n",
        "\n",
        "# Create an input function for validating. drop_remainder = True for using TPUs.\n",
        "val_input_fn = run_classifier.input_fn_builder(\n",
        "    features=val_features,\n",
        "    seq_length=MAX_SEQ_LENGTH,\n",
        "    is_training=False,\n",
        "    drop_remainder=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "K-HW5GQ6DU2y",
        "outputId": "139f4129-cf8a-47e1-8944-d758e3b6e126",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 989
        }
      },
      "source": [
        "#Training the model\n",
        "print(f'Beginning Training!')\n",
        "current_time = datetime.now()\n",
        "estimator.train(input_fn=train_input_fn, max_steps=num_train_steps)\n",
        "print(\"Training took time \", datetime.now() - current_time)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Beginning Training!\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-25-bdfb628bf45b>:33: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:27: The name tf.train.get_or_create_global_step is deprecated. Please use tf.compat.v1.train.get_or_create_global_step instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:32: The name tf.train.polynomial_decay is deprecated. Please use tf.compat.v1.train.polynomial_decay instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/bert/optimization.py:70: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Create CheckpointSaverHook.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into model/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 0 into model/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.9943385, step = 1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:loss = 0.9943385, step = 1\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 24 into model/model.ckpt.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving checkpoints for 24 into model/model.ckpt.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.62784743.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Loss for final step: 0.62784743.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Training took time  0:21:34.120411\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vy-eQ3SyDU20",
        "outputId": "556bd1e7-e0d6-4e2c-a0c2-dc86fa5c486c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 564
        }
      },
      "source": [
        "#Evaluating the model with Validation set\n",
        "estimator.evaluate(input_fn=val_input_fn, steps=None)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
            "/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/indexed_slices.py:424: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
            "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-03-15T13:41:02Z\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Starting evaluation at 2020-03-15T13:41:02Z\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-24\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-03-15-13:41:42\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Finished evaluation at 2020-03-15-13:41:42\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 24: eval_accuracy = 0.6875, false_negatives = 3.0, false_positives = 10.0, global_step = 24, loss = 0.7968761, true_negatives = 1.0, true_positives = 50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving dict for global step 24: eval_accuracy = 0.6875, false_negatives = 3.0, false_positives = 10.0, global_step = 24, loss = 0.7968761, true_negatives = 1.0, true_positives = 50.0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24: model/model.ckpt-24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 24: model/model.ckpt-24\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'eval_accuracy': 0.6875,\n",
              " 'false_negatives': 3.0,\n",
              " 'false_positives': 10.0,\n",
              " 'global_step': 24,\n",
              " 'loss': 0.7968761,\n",
              " 'true_negatives': 1.0,\n",
              " 'true_positives': 50.0}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vr_sIDY-DU22",
        "colab": {}
      },
      "source": [
        "# A method to get predictions\n",
        "def getPrediction(in_sentences):\n",
        "  # Transforming the test data into BERT accepted form\n",
        "  input_examples = [run_classifier.InputExample(guid=\"\", text_a = x, text_b = None, label = 0) for x in in_sentences] \n",
        "  \n",
        "  # Creating input features for Test data\n",
        "  input_features = run_classifier.convert_examples_to_features(input_examples, label_list, MAX_SEQ_LENGTH, tokenizer)\n",
        "\n",
        "  # Predicting the classes \n",
        "  predict_input_fn = run_classifier.input_fn_builder(features=input_features, seq_length=MAX_SEQ_LENGTH, is_training=False, drop_remainder=False)\n",
        "  predictions = estimator.predict(predict_input_fn)\n",
        "  return [(sentence, prediction['probabilities'], prediction['labels']) for sentence, prediction in zip(in_sentences, predictions)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "lvTOzjDFEhTI",
        "outputId": "f1da388f-ed46-4c77-f1fe-d025aa57e189",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "pred_sentences = list(test['Contents'])\n",
        "predictions = getPrediction(pred_sentences)\n",
        "predictions[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 80\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Writing example 0 of 80\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ lil ##fr ##y ##h didn ‚Äô t say mango ju ##ul pods [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] @ lil ##fr ##y ##h didn ‚Äô t say mango ju ##ul pods [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 13451 19699 2100 2232 2134 1521 1056 2360 24792 18414 5313 26723 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 1030 13451 19699 2100 2232 2134 1521 1056 2360 24792 18414 5313 26723 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] smoking a ju ##ul is not better than smoking cigarettes if you ‚Äô re pregnant you shouldn ‚Äô t be smoking . not sorry . your child being healthy should mean more than feeding a habit [UNK] . [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] smoking a ju ##ul is not better than smoking cigarettes if you ‚Äô re pregnant you shouldn ‚Äô t be smoking . not sorry . your child being healthy should mean more than feeding a habit [UNK] . [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9422 1037 18414 5313 2003 2025 2488 2084 9422 15001 2065 2017 1521 2128 6875 2017 5807 1521 1056 2022 9422 1012 2025 3374 1012 2115 2775 2108 7965 2323 2812 2062 2084 8521 1037 10427 100 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 9422 1037 18414 5313 2003 2025 2488 2084 9422 15001 2065 2017 1521 2128 6875 2017 5807 1521 1056 2022 9422 1012 2025 3374 1012 2115 2775 2108 7965 2323 2812 2062 2084 8521 1037 10427 100 1012 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] talk ##in bout ‚Äò ill never smoke a ci ##g ‚Äô but use a ju ##ul . whole ass fool [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] talk ##in bout ‚Äò ill never smoke a ci ##g ‚Äô but use a ju ##ul . whole ass fool [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2831 2378 10094 1520 5665 2196 5610 1037 25022 2290 1521 2021 2224 1037 18414 5313 1012 2878 4632 7966 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2831 2378 10094 1520 5665 2196 5610 1037 25022 2290 1521 2021 2224 1037 18414 5313 1012 2878 4632 7966 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] remember kids next month is no ju ##ul july . can you go the whole month without hitting your ju ##ul [UNK] [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] remember kids next month is no ju ##ul july . can you go the whole month without hitting your ju ##ul [UNK] [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3342 4268 2279 3204 2003 2053 18414 5313 2251 1012 2064 2017 2175 1996 2878 3204 2302 7294 2115 18414 5313 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 3342 4268 2279 3204 2003 2053 18414 5313 2251 1012 2064 2017 2175 1996 2878 3204 2302 7294 2115 18414 5313 100 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:*** Example ***\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:guid: \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] can somebody send a ju ##ul to mexico please [SEP]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:tokens: [CLS] can somebody send a ju ##ul to mexico please [SEP]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2064 8307 4604 1037 18414 5313 2000 3290 3531 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_ids: 101 2064 8307 4604 1037 18414 5313 2000 3290 3531 102 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:input_mask: 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:segment_ids: 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:label: 0 (id = 1)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done calling model_fn.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Graph was finalized.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-24\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Restoring parameters from model/model.ckpt-24\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Done running local_init_op.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('@lilfryh Didn‚Äôt say mango juul pods',\n",
              " array([-2.0719697 , -0.26613083, -2.2281864 ], dtype=float32),\n",
              " 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "YUPK7P4pEjNC",
        "colab": {}
      },
      "source": [
        "enc_labels = []\n",
        "prob_vec = []\n",
        "texts = []\n",
        "for i in range(len(predictions)):\n",
        "  enc_labels.append(label_list[predictions[i][2]])\n",
        "  prob_vec.append(predictions[i][1])\n",
        "  texts.append(predictions[i][0].replace('\\n', ' '))\n",
        "    \n",
        "import numpy as np\n",
        "pd.DataFrame(np.array([texts, prob_vec, enc_labels]).T, columns = ['Text', 'Prob', 'Label']).to_csv('submission_bert.csv', sep = '\\n', index = False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vGJMDCM4EliJ",
        "outputId": "fc0074b3-c1cc-4baf-996f-e0d3f4f9df77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 887
        }
      },
      "source": [
        "!head -n 50 submission_bert.csv"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Text\n",
            "Prob\n",
            "Label\n",
            "@lilfryh Didn‚Äôt say mango juul pods\n",
            "[-2.0719697  -0.26613083 -2.2281864 ]\n",
            "0\n",
            "Smoking a juul is not better than smoking cigarettes if you‚Äôre pregnant you shouldn‚Äôt be smoking. Not sorry. Your child being healthy should mean more than feeding a habit ü§∑üèº‚Äç‚ôÄÔ∏è.\n",
            "[-2.3963385  -0.30291885 -1.770251  ]\n",
            "0\n",
            "talkin bout ‚ÄòiLl nEvEr sMoKe a CiG‚Äô but use a juul. whole ass FOOL ü§£\n",
            "[-2.8800502  -0.21267088 -1.9991827 ]\n",
            "0\n",
            "remember kids next month is no juul july. can you go the whole month without hitting your juul üò≥\n",
            "[-2.5773497  -0.29563612 -1.7149827 ]\n",
            "0\n",
            "Can somebody send a juul to Mexico please\n",
            "[-2.7088277  -0.20980772 -2.098461  ]\n",
            "0\n",
            "PSA YET AGAIN ON THE CARTS. Not only are the DANK VAPES being copied but now KING PENS are too! Know wtf you are buying and be safe ‚ù§Ô∏è\n",
            "[-2.5893118 -0.2060941 -2.1966784]\n",
            "0\n",
            "QT @BIGSANT: üòÇüòÇüòÇ ; Your MCM smokes hookah.\n",
            "[-2.9061027  -0.16225082 -2.3529985 ]\n",
            "0\n",
            "The California Democratic Convention is sponsored by Uber, Visa, Juul, Fox, and AirBnB. WTAF? #CADem2019\n",
            "[-2.4798899  -0.24098144 -2.037215  ]\n",
            "0\n",
            "Still can‚Äôt believe my grandma threwmy vape awayüòÇ\n",
            "[-2.8112497  -0.18360396 -2.2292895 ]\n",
            "0\n",
            "I need to go get coals for my hookah. üò© I ran out!\n",
            "[-2.73514    -0.19319898 -2.2000542 ]\n",
            "0\n",
            "anyone else who doesn't care about spending time with their father wanna go to hookah tonight!\n",
            "[-2.4168227  -0.18585199 -2.5207546 ]\n",
            "0\n",
            "My friend couldn‚Äôt bring his vape in so now I‚Äôm alone at the dayclub who‚Äôs ready for some social anxiety tweets\n",
            "[-1.9422214 -0.2553958 -2.500974 ]\n",
            "0\n",
            "@JaiTheGuy3 My school smells like vape and marijuana all the time LOL\n",
            "[-2.1681483 -0.2539005 -2.2087147]\n",
            "0\n",
            "I feel like my juul is more addicting than cigarettes ever were. But idgaf cuz it‚Äôs under half the cost of smoking and doesn‚Äôt kill me!!!\n",
            "[-1.8766524  -0.30158126 -2.2325883 ]\n",
            "0\n",
            "I love my vape pen. Baked like a potato. Totally a stoner yo! üå¨üåøüçÉ\n",
            "[-3.0512433  -0.19103567 -2.0667481 ]\n",
            "0\n",
            "QT @Alexlovesbooty1: bitch fuck you i texted you back üòÇ ; Since you don't wanna text me back bitch I left my juul pods in your car @xobabykaylee\n",
            "[-2.788066   -0.16865054 -2.3681295 ]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "F_ISe6JxI-ZM",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}